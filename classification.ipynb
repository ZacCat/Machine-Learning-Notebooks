{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "* [1 General Functions](#general_functions)\n",
    "* [1.1 Functions to Save and Open Variables](#open_save)\n",
    "* [2 Datasets](#load_datasets)\n",
    "    * [2.1 Load Reuters Corpus Volume 1 (rcv1) Dataset](#load_rcv1)\n",
    "    * [2.2 Dataset Attributes of rcv1](#attributes_rcv1)\n",
    "    * [2.3 Load Modified National Institute of Standards and Technology (MNIST) Dataset](#load_mnist)\n",
    "    * [2.4 Train/Test Split](#train_test_split)\n",
    "    * [2.5 Dataset Attributes of MNIST](#attributes_mnist)\n",
    "* [3 Document Classification](#document_classification)\n",
    "    * [3.1 Naive Bayes](#naive_bayes)\n",
    "        * [3.1.1 Naive Bayes on rcv1](#nb_rcv1)\n",
    "        * [3.1.2 Naive Bayes on MNIST](#nb_mnist)\n",
    "    * [3.2 Generating Predictions](#generating_predictions)\n",
    "    * [3.3 Evaluating Predictions](#evaluating_predictions)\n",
    "    * [3.4 Recall vs Precision Graph](#recall_precision_graph)\n",
    "        * [3.4.1 Recall-Precision Graph for Naive Bayes with rcv1](#graph_nb_rcv1)\n",
    "        * [3.4.2 Recall-Precision Graph for for Naive Bayes with MNIST](#graph_nb_mnist)\n",
    "    * [3.5 K-Folds Cross-Validation](#k_folds)\n",
    "    * [3.6 Support Vector Machines (SVM)](#svm)\n",
    "        * [3.6.1 SVM on rcv1](#svm_rcv1)\n",
    "        * [3.6.2 SVM on mnist](#svm_mnist)\n",
    "    * [3.7 k-Nearest Neighbors (kNN)](#knn)\n",
    "        * [3.7.1 kNN on rcv1](#knn_rcv1)\n",
    "        * [3.7.2 kNN on mnist](#knn_mnist)\n",
    "    * [3.8 Decision Trees](#decision_trees)\n",
    "        * [3.7.1 Decision Trees on rcv1](#dt_rcv1)\n",
    "        * [3.7.2 Decision Trees on mnist](#dt_mnist)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Terminology <a id='basic_terminology'></a>\n",
    "\n",
    "\n",
    "\n",
    "The following table shows a sample of the Iris data set. The Iris data set will be used to explain important foundational terminology. This data set consists of various measurements of iris flowers and the species of that particular flower. \n",
    "\n",
    "|Sepal length | Sepal width | Petal length | Petal width |  Species   |\n",
    "|-------------|-------------|--------------|-------------|------------|\n",
    "| 5.1 | 3.5 | 1.4 | 0.2 | setosa   |\n",
    "| 4.9 | 3.0 | 1.4 | 0.2 | setosa   |\n",
    "| 4.7 | 3.2 | 1.3 | 0.2 | setosa   |\n",
    "| 7.0 | 3.2 | 4.7 | 1.4 | versicolor  |\n",
    "| 6.4 | 3.2 | 4.5 | 1.5 | versicolor  |\n",
    "| 6.9 | 3.1 | 4.9 | 1.5 | versicolor  |\n",
    "| 6.3 | 3.3 | 6.0 | 2.5 | virginica  |\n",
    "| 5.8 | 2.7 | 5.1 | 1.9 | virginica  |\n",
    "| 7.1 | 3.0 | 5.9 | 2.1 | virginica  |\n",
    "\n",
    "The rows of this table represent individual data points, in this case individual iris flowers. The columns are called the <b>features</b> or <b>predictors</b>, they will be used to infer the class labels of new data. In the case of the iris data set the species is what we would like to predict. So this data set has four predictors: Sepal length, Sepal width, Petal length, and Petal width. The Species column represents the <b>true label</b> of each data point.  In this data set there are 3 possible class labels: setosa, versicolor, and virginica. The labeled data gives examples of actual members of each class, this information is used by the classification algorithm to predict the class labels of new data.<br>\n",
    "<br>\n",
    "A <b>feature vector</b> is simply a row from a data set, using our iris example suppose we have the following feature vector: <br>\n",
    "$$f_1 = (5.1, \\ 3.5, \\ 1.4, \\ 0.2)$$\n",
    "$\\ f_1$ corresponds to a iris flower with a sepal length of 5.1, a sepal width of 3.5, a petal length of 1.4, and a petal width of 0.2. <br>\n",
    "\n",
    "### Types of classification problems\n",
    "<b>Binary Classification</b>: There are exactly two possible classes. For example, imagine a spam filter for a email service, a message can be classified as either spam or not spam. \n",
    "\n",
    "<b>Multiclass Classification</b>: There are more than two classes. Imagine classifying hand-written digits, there are 10 possible class labels one for each number 0-9.\n",
    "\n",
    "<b>Muti-label Classification</b>: There are more than two classes and each training instance can be assigned more than one class label. Imagine classifying images of fruit. A picture could contain only an apple or apples and pears or perhaps oranges, bananas and apples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Functions <a id='general_functions'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to Save and Open Variables <a id='open_save'></a>\n",
    "\n",
    "Since it is not uncommon for a machine learning task to take a long time it is good practice to save variables that may be needed in the future. This can be achieved by using the <a target=\"_top\" href=\"https://docs.python.org/3/library/pickle.html\">pickle</a> module. This package allows a variable up to 4gb to be saved. This limitation is why the 'metrics' variables are saved as individual items instead of a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save variables to file\n",
    "import pickle\n",
    "\n",
    "def save_var(variable_name):\n",
    "    \"\"\" Saves the variable with the provided variable name \n",
    "         in the global namespace to the ./vars folder \n",
    "         with the provided same name \"\"\"\n",
    "    \n",
    "    with open('./vars/' + variable_name,'wb') as my_file_obj:\n",
    "        pickle.dump(globals()[variable_name], my_file_obj, protocol=4)\n",
    "\n",
    "def save_var_list(variable_name_list):\n",
    "    \"\"\" Saves each variable with the provided variable name \n",
    "         in the global namespace to the ./vars folder \n",
    "         with the provided same name \"\"\"\n",
    "    for name in variable_name_list:\n",
    "        with open('./vars/' + name,'wb') as my_file_obj:\n",
    "            pickle.dump(globals()[name], my_file_obj, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def open_var(file_name):\n",
    "    \"\"\" Returns the variable saved with the provided \n",
    "         file name located in the ./vars folder\"\"\"\n",
    "    \n",
    "    file_object = open('./vars/' + file_name,'rb')  \n",
    "\n",
    "    loaded_var = pickle.load(file_object)\n",
    "    \n",
    "    return loaded_var\n",
    "\n",
    "def open_var_list(file_name_list):\n",
    "    \"\"\" Loads a variable corresponding to each file name\n",
    "         in file_name_list to the global namespace. \"\"\"\n",
    "    \n",
    "    for file_name in file_name_list:\n",
    "        globals()[file_name] = open_var(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time open_var_list(['rcv1_train', 'rcv1_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time save_var_list(['mnist', 'mnist_train', 'mnist_test', 'rcv1_train', 'rcv1_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_Part:\n",
    "    \"\"\" Represents a dataset with attributes\n",
    "         data and target \"\"\"\n",
    "    \n",
    "    data = None\n",
    "    target = None\n",
    "    def __init__(self, X, y):\n",
    "        self.data = X\n",
    "        self.target = y\n",
    "\n",
    "%time open_var_list(['mnist_train', 'mnist_test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets <a id='load_datasets'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a target=\"_top\" href=\"http://scikit-learn.org/stable/datasets/rcv1.html\">Load Reuters Corpus Volume I (rcv1) Dataset</a> <a id='load_rcv1'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn includes functions to easily load some popular datasets. One of the included datasets is rcv1. This dataset can be loaded completly or broken into test and train subsets. This dataset consists of over 800,000 manually categorized news stories. The data is represented by cosine-normalized log TF-IDF vectors and the labels are 103 classes with binary values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_rcv1\n",
    "\n",
    "%time rcv1 = fetch_rcv1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_rcv1\n",
    "\n",
    "%time rcv1_train, rcv1_test = (fetch_rcv1(subset='train'), fetch_rcv1(subset='test'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Attributes of rcv1 <a id='attributes_rcv1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets loaded from scikit-learn will typically have several attributes.\n",
    "\n",
    "   1. __data__ - a scipy <a target=\"_top\" href=\"https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.sparse.csr_matrix.html\">compressed row storage (CSR) sparce matrix</a>. Non-zero values are cosinne-normalized, log TF-IDF vectors. The shape is (num_samples, num_features)\n",
    "   2. __target__ - a scipy CSR sparse matrix. Maps each sample to relavent categories (sometimes refered to as labels). The shape is (num_samples, num_categories).\n",
    "   3. __sample_id__ - a <a target=\"_top\" href=\"https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.ndarray.html\">numpy n-dimensional array</a> (ndarray) associating each sample's ID to its sample number\n",
    "   4. __target_names__ - a ndarray of target names (can be thought of as topics or categories) corresponding to the category mapping in __(2)__. Each sample belongs to n categories, where 1 $\\le$ n $\\le$ 13.\n",
    "   5. __DESCR__ - a description of the dataset\n",
    "   \n",
    "The shape attribute gives the dimensions of the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nonzero(matrix):\n",
    "    \"\"\" Returns the percent of items in the provided \n",
    "         matrix that are not 0.\n",
    "         \n",
    "        Params:\n",
    "          matrix -- a csr sparse matrix \"\"\"\n",
    "    \n",
    "    nonzero = (matrix.count_nonzero() / (matrix.shape[0] * matrix.shape[1])) * 100\n",
    "    # Check value is valid\n",
    "    assert nonzero <= 100\n",
    "    assert nonzero >= 0\n",
    "    \n",
    "    return nonzero\n",
    "\n",
    "def print_rcv1_attributes(dataset):\n",
    "    \"\"\" Prints attributes of the provided dataset.\n",
    "    \n",
    "        Params:\n",
    "          dataset -- the RCV1 full dataset or a subset \"\"\"\n",
    "    \n",
    "    print(f'  rcv1 type: {type(dataset)}')\n",
    "    \n",
    "    print ('data:')\n",
    "    print(f'      shape: {dataset.data.shape}')\n",
    "    print(f'  data type: {dataset.data.dtype}')\n",
    "    print(f' array type: {type(dataset.data)}')\n",
    "    print(f'    nonzero: {get_nonzero(dataset.data):0.4f}%\\n')\n",
    "\n",
    "    print('target:')\n",
    "    print(f'      shape: {dataset.target.shape}')\n",
    "    print(f'  data type: {dataset.target.dtype}')\n",
    "    print(f' array type: {type(dataset.target)}')\n",
    "    print(f'    nonzero: {get_nonzero(dataset.target):0.4f}%\\n')\n",
    "\n",
    "    print('sample_id:')\n",
    "    print(f'      shape: {dataset.sample_id.shape}')\n",
    "    print(f'  data type: {type(dataset.sample_id[3])}')\n",
    "    print(f' array type: {type(dataset.sample_id)}\\n')\n",
    "\n",
    "    print('target_names:')\n",
    "    print(f'      shape: {dataset.target_names.shape}')\n",
    "    print(f'  data type: {type(dataset.target_names[3])}')\n",
    "    print(f' array type: {type(dataset.target_names)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('rcv1 dataset attributes')\n",
    "print_rcv1_attributes(rcv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('rcv1 training subset attributes:')\n",
    "print_rcv1_attributes(rcv1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nrcv1 testing subset attributes:')\n",
    "print_rcv1_attributes(rcv1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a target=\"_top\" href=\"http://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_mldata.html\">Modified National Institute of Standards and Technology (MNIST) Dataset</a> <a id='load_mnist'></a> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another included dataset is MNIST. This dataset is 70,000 handwritten digits represented by 28x28 pixel images. The classes correspond to the number shown in the image. Since each image is 28x28 each pixel is a feature giving each document 784 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "\n",
    "mnist = fetch_mldata('MNIST original')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split <a id='train_test_split'></a>\n",
    "\n",
    "Since MNIST does not have a default train/test set like rcv1 we will use a train/test split. This is when a dataset is broken into two parts, one to train the classifier and one to test it. When decomposing the dataset it is important to ensure equal representation of each class. MNIST is sorted by  digit; therefore, if the dataset is simply partitioned in order there may be no instances of a particular class. This can be alleviated by shuffling the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# To keep the .data and .target format consistent \n",
    "class Dataset_Part:\n",
    "    \"\"\" Represents a dataset with attributes\n",
    "         data and target \"\"\"\n",
    "    \n",
    "    data = None\n",
    "    target = None\n",
    "    def __init__(self, X, y):\n",
    "        self.data = X\n",
    "        self.target = y\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(mnist.data, mnist.target, test_size=.33, random_state=35)\n",
    "mnist_train, mnist_test = Dataset_Part(X_train, y_train), Dataset_Part(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Attributes of MNIST <a id='attributes_mnist'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets loaded from scikit-learn will typically have several attributes.\n",
    "\n",
    "   1. __data__ - a <a target=\"_top\" href=\"https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.ndarray.html\">numpy n-dimensional array</a> (ndarray). The value of each feature corresponds to the intensity of a pixel. Each feature is represented by an intensity 0 (white) to 255 (black). The shape is (num_samples, num_features).\n",
    "   2. __target__ - a <a target=\"_top\" href=\"https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.ndarray.html\">numpy n-dimensional array</a> (ndarray) associating each sample's ID to the value of the handwritten digit.\n",
    "   \n",
    "The shape attribute gives the dimensions of the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_avg_nonzero(subset):\n",
    "    \"\"\" Returns the percent of items in the provided \n",
    "         list matricies that are not 0.\n",
    "         \n",
    "        Params:\n",
    "          matrix -- a csr sparse matrix \"\"\"\n",
    "    \n",
    "    return (np.count_nonzero(subset) / (subset.shape[1] * subset.shape[0])) * 100\n",
    "\n",
    "def print_mnist_attributes(dataset):\n",
    "    \"\"\" Prints attributes of the provided dataset.\n",
    "    \n",
    "        Params:\n",
    "          dataset -- the mnist full dataset \"\"\"\n",
    "    \n",
    "    print(f'     mnist type: {type(dataset)}')\n",
    "    \n",
    "    print ('data:')\n",
    "    print(f'          shape: {dataset.data.shape}')\n",
    "    print(f'      data type: {dataset.data.dtype}')\n",
    "    print(f'     array type: {type(dataset.data)}')\n",
    "    print(f' nonzero pixels: {get_avg_nonzero(dataset.data):0.4f}%\\n')\n",
    "\n",
    "    print('target:')\n",
    "    print(f'          shape: {dataset.target.shape}')\n",
    "    print(f'      data type: {dataset.target.dtype}')\n",
    "    print(f'     array type: {type(dataset.target)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MNIST train dataset attributes')\n",
    "print_mnist_attributes(mnist_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MNIST test dataset attributes')\n",
    "print_mnist_attributes(mnist_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to view a document as an image by reshaping the array to a 28x28 matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "def print_rand_digit():  \n",
    "    # Get a random document\n",
    "    rand_index = random.randint(0,70000)\n",
    "    rand_digit = mnist_train.data[rand_index]\n",
    "    # Reshape it to the size of the image\n",
    "    rand_digit_image = rand_digit.reshape(28,28)\n",
    "\n",
    "    # Some information\n",
    "    print(f'\\tIndex: {rand_index}\\tLabel: {mnist_train.target[rand_index]:.0f}')\n",
    "    # Show the image\n",
    "    plt.imshow(rand_digit_image, cmap=matplotlib.cm.binary, interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "print_rand_digit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a target=\"_top\" href=\"http://scikit-learn.org/stable/modules/naive_bayes.html\">Naive Bayes</a> <a id='naive_bayes'></a>\n",
    "A supervised learning algorithm based on using Bayes' theorem. This method assumes independence between each pair of features.\n",
    "\n",
    "Bayes Theorem from eq. 1 in [zhang-2004]:\n",
    "\\begin{equation}\n",
    "p(c \\mid x_1, . . ., x_n) = \\frac{P(c) P(a_1, . . ., a_n | y)} {P(a_1, . . ., a_n)}\n",
    "\\end{equation}\n",
    "\n",
    "By assuming all attributes are independent we can further simplify $p(a_1, . . ., a_n \\mid c)$ eq. 2 from [zhang-2008], this is the naive assumption of naive bayes.\n",
    "\n",
    "\\begin{equation}\n",
    "p(x_1, . . ., x_n \\mid c) = \\prod_{i = 1}^{n} P(x_i | c)\n",
    "\\end{equation}\n",
    "\n",
    "This gives us our classification rule, as shown in eq. 3 from [zhang-2008]. \n",
    "\n",
    "\\begin{equation}\n",
    "C_{nb}(x_1, . . ., x_n) = \\underset{c}{arg} \\max p(c)  \\prod_{i = 1}^{n} P(x_i | c)\n",
    "\\end{equation}\n",
    "\n",
    "SciKit Learn supports several Naive Bayes implimentations. \n",
    "1. <a target=\"_top\" href=\"http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html\">__Gaussian Naive Bayes__</a> - In this implementation the likelihood of the features is assumed to be Gaussian. Gaussian distributions are more commonly reffered to as the normal distribution and in this instance will be represented as $g(x_i, \\mu_{i,c}, \\sigma_{i,c})$, where $\\mu$ is the mean and $\\sigma$ is the typical deviation. The probability of a document vector $\\vec{x}$ using multinomial Naive Bayes is shown in section 2.2 of [metsis-2006]. Let $\\vec{x}$ represent the term frequency vector of the document to be evaulated, where $x_i$ represents the number of times $t_i$ appears in the document.\n",
    "\n",
    "\\begin{equation}\n",
    "    p(\\vec{x} \\mid c) =  \\prod_{i = 1}^{m} g(x_i, \\mu_{i,c}, \\sigma_{i,c})\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualization of a normal distribution\n",
    "\n",
    "#feel free to edit the mean and stdDiv variables to see\n",
    "#how the distribution is affected\n",
    "\n",
    "mean = 0\n",
    "stdDev = 1 #standard deviation\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "import scipy\n",
    "\n",
    "\n",
    "\n",
    "bounds = np.linspace(mean - 3*stdDev, mean + 3*stdDev, 100)\n",
    "normalCurve = scipy.stats.norm.pdf(x, mean, stdDev)\n",
    "plt.plot(bounds,normalCurve)\n",
    "plt.fill_between(bounds,normalCurve, hatch='/')\n",
    "plt.title('Gaussian (Normal) Distribution with Mean ' + str(mean) + ' and Standard Deviation ' + str(stdDev))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#!!!!!!!Fill in under the curve\n",
    "#add unuiqe variable names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. <a target=\"_top\" href=\"http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">__Multinomial Naive Bayes__</a> - In this implementation the likelihood of the features is assumed to follow a multinomial distribution. Typically used in text classification. This model is useful in text calssification because it uses word frequency in classification decisions [mccallum-1998]. The probability of a document vector $\\vec{x}$ using multinomial Naive Bayes is shown in section 2.2 of [metsis-2006]. Let $\\vec{x}$ represent the term frequency vector of the document to be evaulated, where $x_i$ represents the number of times $t_i$ appears in document $d$, and let $d$ be a bag of words representation of the document.\n",
    "\n",
    "\\begin{equation}\n",
    "    p(\\vec{x} \\mid c) =  p(\\mid d \\mid) \\cdot \\mid d \\mid ! \\cdot  \\prod_{i = 1}^{m} \\frac{p(t_i \\mid c)^{x_i} }{x_i!}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multinomial distribution visualization\n",
    "\n",
    "from scipy.stats import multinomial\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#changes the values of proabalityVector to see how the observed distribution\n",
    "#is changed, NOTE: all probabilites must sum up to 1\n",
    "probabilityVector = [0.1, 0.2, 0.3, 0.2, 0.1, 0.1] #!!!!!!add more descripiton\n",
    "\n",
    "n = 100\n",
    "\n",
    "outcomes = multinomial.rvs(n, probabilityVector, size=1, random_state=0)\n",
    "\n",
    "outcomes = outcomes[0]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "index = np.arange(6)\n",
    "barWidth = 0.35\n",
    "\n",
    "\n",
    "bars = ax.bar(index, outcomes, barWidth, color='b',label='Outcomes',alpha=0.5)\n",
    "\n",
    "ax.set_xlabel('Side', fontsize=14)\n",
    "ax.set_ylabel('Frequency', fontsize=14)\n",
    "ax.set_title('Outcomes of rolling a loaded die 100 times', fontsize=16)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. <a target=\"_top\" href=\"http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html\">__Bernoulli Naive Bayes__</a> - This implementaiton assumes the data follows multivariate Bernoulli distributions. Multiple features are allowed but each feature is assumed to be a binary variable [mccallum-1998]. The probability of a binary document vector $\\vec{x}$ using multivatiate Bernoulli Naive Bayes is shown in section 2.1 of [metsis-2006]. Let $\\vec{x}$ be a binary vector where $x_i$ represents whether term $t_i$ is in the document.\n",
    "\n",
    "\\begin{equation}\n",
    "    p(\\vec{x} \\mid c) =  \\prod_{i = 1}^{m} p(t_i \\mid c)^{x_i} \\cdot (1 - p(t_i \\mid c)^{(1 - x_i)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bernoulli Distribution\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of these restrictions only Multinomial Naive Bayes will be appropriate for the RCV1 dataset. There is an additional step required because Naive Bayes does not typically predict multilple labels. This means an additional strategy must be implemented. One commonly used startegy is known as one-vs-all <a target=\"_top\" href=\"http://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsRestClassifier.html#sklearn.multiclass.OneVsRestClassifier\">one-vs-the-rest</a> in scikit learn. This strategy works by using one classifier for each label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes on rcv1 <a id='nb_rcv1'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "\n",
    "from sklearn.datasets import fetch_rcv1\n",
    "\n",
    "#load the rcv1 dataset if its has not aready been loaded\n",
    "if('rcv1_train' not in locals() or 'rcv1_test' not in locals()):\n",
    "    print('Loading datasets')\n",
    "    rcv1_train, rcv1_test = (fetch_rcv1(subset='train'), fetch_rcv1(subset='test'))\n",
    "\n",
    "#clf_NB_rcv1 is a list of naive bayes classifiers each with a different value for the hyper(tunning) parameter alpha.\n",
    "#So we are training four different naive bayes classifiers\n",
    "#clf is a abbreviation of the word classifier\n",
    "clf_NB_rcv1 = [OneVsRestClassifier(MultinomialNB(alpha=1), n_jobs=-1),\n",
    "          OneVsRestClassifier(MultinomialNB(alpha=.25), n_jobs=-1),\n",
    "          OneVsRestClassifier(MultinomialNB(alpha=.05), n_jobs=-1),\n",
    "          OneVsRestClassifier(MultinomialNB(alpha=.01), n_jobs=-1)]\n",
    "    \n",
    "# rcv1 training set does not contain all the labels and throws a warning.\n",
    "# This with statement will suppress these warnings.\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "    #this list comprehension fits each naive bayes classifier to the training data set \n",
    "    %time clf_NB_rcv1 = [clf.fit(rcv1_train.data, rcv1_train.target) for clf in clf_NB_rcv1]\n",
    "\n",
    "titles_NB_rcv1 = ['alpha=1', 'alpha=.25', 'alpha=.05', 'alpha=.01']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes on MNIST<a id='nb_mnist'></a> \n",
    "Since MNIST is much smaller and not a multioutput problem it will be used to demenstrate Multinomial Niave Bayes, Gaussian Niave Bayes, and Bernoulli Niave Bayes. Notice that the OneVsRestClassifier is not necessary when using MNIST because it is not a multioutput dataset (meaning each sample only has one label)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from sklearn.datasets import fetch_mldata\n",
    "\n",
    "from datasets import load_mnist\n",
    "\n",
    "#load mnist dataset\n",
    "mnist_train, mnist_test = load_mnist()\n",
    "\n",
    "#clf_NB_mnist is a list of naive bayes classifiers each using a different base distribution,\n",
    "#namely the Multinomial distribution, the Gaussian (normal) distribution, and the Bernulli distribution\n",
    "clf_NB_mnist = [MultinomialNB(),\n",
    "          GaussianNB(),\n",
    "          BernoulliNB()]\n",
    "\n",
    "#fit each of the classifiers to the training data\n",
    "%time clf_NB_mnist = [clf.fit(mnist_train.data, mnist_train.target) for clf in clf_NB_mnist]\n",
    "\n",
    "titles_NB_mnist = ['Multinomial', 'Gaussian', 'Bernoulli']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Predictions <a id='generating_predictions'></a>\n",
    "\n",
    "Classifiers in machine learning are used to predict the label(s) of a new document that the classifier has never seen. Niave Bayes generates predictions by finding the label(s) with the highest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict class labels for the test data\n",
    "%time pred_NB_rcv1 = [clf.predict(rcv1_test.data) for clf in clf_NB_rcv1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict class labels for the test data\n",
    "%time pred_NB_mnist = [clf.predict(mnist_test.data) for clf in clf_NB_mnist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Predictions <a id='evaluating_predictions'></a>\n",
    "When testing a machine learning algorithm it is difficult to determine how a classifier performs by looking at predictions, so several metrics are commonly used to evaluate their performance.\n",
    "\n",
    "1. __accuracy__ - The percentage of labels predicted correctly.\n",
    "+ __precision__ - The ratio of true positives to true positives and false positives.\n",
    "+ __recall__ - The ratio of true positives to true positives and false negatives.\n",
    "+ __average precision__ - The weighted mean of the precision achieved at each recall threshold.\n",
    "\n",
    "The term 'micro' average refers to calculating the average of each label weighted with respect to how frequently they occur. This is most appropriate for the RCV1 dataset because the labels do not occur with the same frequency. Information on additional averaging methods can be found <a target=\"_top\" href=\"http://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html#sklearn.metrics.average_precision_score\">here</a>.\n",
    "\n",
    "The term 'macro' average refers to calculating the average of each label without taking the label frequency into account. This is appropriate for MNIST because each label occurs with the same frequency. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, average_precision_score, f1_score, precision_score, recall_score\n",
    "from scipy.sparse import issparse\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import arange, matrix\n",
    "\n",
    "def get_scores(target, prediction, avg_type):\n",
    " \n",
    "    scores = { 'accuracy': accuracy_score(target, prediction),\n",
    "               'f1' : f1_score(target, prediction, average=avg_type),\n",
    "               'recall' : recall_score(target, prediction, average=avg_type),\n",
    "               'precision' : precision_score(target, prediction, average=avg_type) }\n",
    "    \n",
    "    return scores\n",
    "\n",
    "def graph_scores(scores, keys, title):\n",
    "\n",
    "    count = len(scores)\n",
    "    metric = tuple(t.title() for t in scores[0].keys())\n",
    "    colors=['b', 'g', 'r', 'c', 'm', 'y']\n",
    "    bar_width = .81 / count\n",
    "    y_vals = arange(len(metric))\n",
    "    \n",
    "    for i, score in enumerate(scores):\n",
    "        plt.bar(y_vals + bar_width * (i + ((3 - count) / 2)) , tuple(score.values()), width=bar_width, align='center', alpha=0.2, color=colors[i], linewidth=1, edgecolor='k')\n",
    "\n",
    "    plt.legend(keys, bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)\n",
    "    plt.xticks(y_vals + bar_width, metric)\n",
    "    plt.ylabel('Score')\n",
    "    plt.ylim(0.,1.)\n",
    "    plt.title(f'Evaluation Metrics for {title}\\n\\n')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def print_scores(scores, avg_type):\n",
    "    print(f'Accuracy: {scores[\"accuracy\"]:0.4f}')\n",
    "    print(f'{avg_type}-averaged F1: {scores[\"f1\"]:0.4f}')\n",
    "    print(f'{avg_type} averaged recall: {scores[\"recall\"]:0.4f}')\n",
    "    print(f'{avg_type} averaged precision: {scores[\"precision\"]:0.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scores for Naive Bayes on RCV1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scoring import get_scores, print_scores\n",
    "\n",
    "scores_NB_rcv1 = [get_scores(rcv1_test.target, pred, 'micro') for pred in pred_NB_rcv1]\n",
    "\n",
    "for title, score in zip(titles_NB_rcv1, scores_NB_rcv1):\n",
    "    print(f'\\n{title}')\n",
    "    print_scores(score, 'micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scoring import graph_scores\n",
    "\n",
    "graph_scores(scores_NB_rcv1, titles_NB_rcv1, 'Naive Bayes on RCV1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scores for Naive Bayes on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scoring import get_scores, print_scores\n",
    "\n",
    "scores_NB_mnist = [get_scores(mnist_test.target, pred, 'macro') for pred in pred_NB_mnist]\n",
    "\n",
    "for title, score in zip(titles_NB_mnist, scores_NB_mnist):\n",
    "    print(f'\\n{title} NB')\n",
    "    print_scores(score, 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scoring import graph_scores\n",
    "\n",
    "graph_scores(scores_NB_mnist, titles_NB_mnist, 'Naive Bayes on MNIST')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall vs Precision Graph <a id='recall_precision_graph'></a>\n",
    "\n",
    "Recall and precision are inversely related, as you increase one the other decreases. Because of this it is often nessicary to adjust the implementation to get the ideal precision or recall for the specific task at hand. A good way to visualize this tradeoff is by graphing recall vs precision at different prediction thresholds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score, f1_score, precision_score, recall_score, precision_recall_curve\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "from scipy.sparse import issparse\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def graph_precision_recall(target, conf_list, titles, classes=[]):\n",
    "    colors = iter(['b','r','g','c','m','k'])\n",
    "\n",
    "    plt.figure()\n",
    "    \n",
    "    for confidence in conf_list:\n",
    "        if issparse(target):\n",
    "            target = target.toarray()\n",
    "        \n",
    "        # If target is multiclass it must be binarized\n",
    "        if not np.array_equal(target, target.astype(bool)):\n",
    "            classes_auto = np.unique(target)\n",
    "            target = label_binarize(target, classes_auto if len(classes) < len(classes_auto) else classes)\n",
    "\n",
    "        # A \"micro-average\": quantifying score on all classes jointly\n",
    "        precision, recall, threshold = precision_recall_curve(target.ravel(), confidence.ravel())\n",
    "        average_precision = average_precision_score(target, confidence, average=\"micro\")\n",
    "\n",
    "        \n",
    "        plt.step(recall, precision, color=next(colors), alpha=.5,where='post')\n",
    "\n",
    "    plt.legend(titles, bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)\n",
    "\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title(f'Precision-Recall Curves')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision Recall Curve for Naive Bayes on RCV1 <a id='graph_nb_rcv1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scoring import graph_precision_recall\n",
    "\n",
    "%time confidence_NB_rcv1 = [clf.predict_proba(rcv1_test.data) for clf in clf_NB_rcv1]\n",
    "%time graph_precision_recall(rcv1_test.target, confidence_NB_rcv1, titles_NB_rcv1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision Recall Curve for Naive Bayes on MNIST <a id='graph_nb_mnist'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scoring import graph_precision_recall\n",
    "\n",
    "%time confidence_NB_mnist = [clf.predict_proba(mnist_test.data) for clf in clf_NB_mnist]\n",
    "%time graph_precision_recall(mnist_test.target, confidence_NB_mnist, titles_NB_mnist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a target=\"_top\" href=\"http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html\">K-Folds Cross-Validation</a> <a id='k_folds'></a>\n",
    "\n",
    "To remove bias from a train/test split it is common practice to use K-Folds cross-validation, typically k = 10. This splits the dataset into k segments. With these k segments k - 1 are used to train a classifier while the last one is used to test. This is repeated until all k segments have been used as the testing segment. This can be easily implemented through the sklearn function <a target=\"_top\" href=\"http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html\">cross_val_score</a>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1 score = 0.8340\n",
      "fold 2 score = 0.8191\n",
      "fold 3 score = 0.8240\n",
      "fold 4 score = 0.8189\n",
      "fold 5 score = 0.8198\n",
      "fold 6 score = 0.8314\n",
      "fold 7 score = 0.8275\n",
      "fold 8 score = 0.8286\n",
      "fold 9 score = 0.8405\n",
      "fold 10 score = 0.8545\n",
      "average score 0.8298\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "from sklearn.datasets import fetch_mldata\n",
    "\n",
    "from datasets import load_mnist\n",
    "\n",
    "#load mnist dataset\n",
    "#mnist_train, mnist_test = load_mnist()\n",
    "\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "\n",
    "scores = cross_val_score(BernoulliNB(), mnist.data, mnist.target, cv=10, scoring='f1_macro')\n",
    "\n",
    "for k, score in enumerate(scores, 1):\n",
    "    print(f'fold {k} score = {score:0.4f}')\n",
    "\n",
    "print(f'average score {sum(scores) / len(scores):0.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parametric Models <a id='parametric_models'></a>\n",
    "\n",
    "Parametric models make assumptions about the shape of the underlying function generating the data. For example, linear regression assumes that a linear function describes the data. Parametric models also include the same number of parameters no matter the size of the data set. These models tend to be more interpretable than non-parametric models but can perform poorly if they assumptions made about the data do not hold.\n",
    "\n",
    "**Examples:**\n",
    "- Linear Regression\n",
    "- Naive Bayes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-parametric Models <a id='non-parametric_models'></a>\n",
    "\n",
    "Non-parametric models make no assumption about the shape of the underlying function generating the data. These models tend to be less interpretable than parametric models. These types of models often need more training data to perform well.\n",
    "\n",
    "**Examples:**\n",
    "- k-Nearest Neighbors\n",
    "- Decision Trees\n",
    "- Support Vector Machines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-vs-The-Rest and One-vs-One Classification <a id='one_vs_rest'></a>\n",
    "\n",
    "One-vs-Rest, also called One-vs-All, and One-vs-One classification are a methods used to overcome the binary classification restriction inherent to some classification algorithms. These methods will allow us to use Support Vector Machines and Naive Bayes Classifiers for multiclass classification problems.\n",
    "\n",
    "### One-vs-The-Rest\n",
    "One-vs-the-rest classification involves training a separate classifier for each class, the instances of that class are used as positive examples while all other training examples are used as negative examples. This method requires that the classification algorithm give a confidence measurement for its predicted label. To predict the class of a test instance all classifiers classify the test instance, the label given by classifier that reports the highest confidence is chosen. One-vs-The-Rest is a more computationally efficient method since it requires $O(K)$ classifiers, where $K$ is the number of classes. The performance of the classifiers can be skewed since negative examples are over represented. <br>\n",
    "The Iris data set has classes setosa, versicolor, and virginica. To train a one-vs-rest classifier we would train one classifier to identify setosa using versicolor and virginica as negative examples. Then we would train a classifier to identify versicolor using the instances of virginica and setosa as negative examples. Finally, we train the last classifier to recognize virginica using setosa and versicolor as negative examples. We are effectively training a classifier for each class label.<br> \n",
    "\n",
    "### One-vs-One\n",
    "For One-vs-One classification we train $\\frac{K (K - 1)}{2} $ classifiers, where $K$ is the number of classes for the classification problem. Each classifier is trained to differentiate between a pair of classes. To classify a new test instance a voting system is applied, each classifier is run on the sample each prediction for a specific class is considered a vote for that class. The class label which receives the most votes will be returned as the predicted label. There is a possibility that the vote may lead to a tie. This method is more computationally expensive requiring $O(K^{2})$ classifiers. <br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a target=\"_top\" href=\"http://scikit-learn.org/stable/modules/svm.html\">Support Vector Machines (SVM)</a> <a id='svm'></a>\n",
    "    \n",
    "A supervised learning that works by seperating the samples into categories seperated by a hyperplane, or set of hyperplanes. Since the hyperplane that that seperates them is not typically unique SVM finds the hyperplane with the maximum margin between classes[boser-1992]. Support Vector Machines are binary classifiers, but by combining multiple classifiers it can be expanded to fit a multi-class classification problem [wu-2004]. The decision function for a SVM can be found in [boser-1992] eq. (4). Let $\\alpha_k$ be the adjustable paramaters (weights), $x_k$ be the patterns for training, $b$ be the bias, and the function $K$ be the kernel function [boser-1992] [guyon-1993].\n",
    "\n",
    "\\begin{equation}\n",
    "    D(x) = \\sum_{k=1}^p \\alpha_k K(x_k, x) + b\n",
    "\\end{equation}\n",
    "\n",
    "SVM use kernel functions to compute the similarity between data points. Some of the most common are:\n",
    "\n",
    "+ polynomial with order $q$ [boser-1992]\n",
    "\\begin{equation}\n",
    "    K(x, x') = ( x \\cdot x' + 1)^q\n",
    "\\end{equation}\n",
    "+ radial basis function (rbf) - From eq (9) [guyon-1993]\n",
    "\\begin{equation}\n",
    "    K(x, x') = \\exp \\bigg\\{ - \\frac{\\mid \\mid x - x_i \\mid \\mid^2}{\\sigma^2} \\bigg\\}\n",
    "\\end{equation}\n",
    "+ sigmoid - From eq (2.69) [scholkopf-2009]\n",
    "\\begin{equation}\n",
    "    K(x, x') = tanh(\\kappa \\langle x,x' \\rangle + \\vartheta)\n",
    "\\end{equation}\n",
    "\n",
    "The kernel used can significantly impact the accuracy of a classifier. More information on kernels is provided <a target=\"_top\" href=\"http://scikit-learn.org/stable/modules/metrics.html\">here</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines on RCV1 <a id='svm_rcv1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.5 s, sys: 1.81 s, total: 6.31 s\n",
      "Wall time: 6.54 s\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.datasets import fetch_rcv1\n",
    "\n",
    "#load the rcv1 dataset if its has not aready been loaded\n",
    "if('rcv1_train' not in locals() or 'rcv1_test' not in locals()):\n",
    "    print('Loading datasets')\n",
    "    rcv1_train, rcv1_test = (fetch_rcv1(subset='train'), fetch_rcv1(subset='test'))\n",
    "\n",
    "\n",
    "clf_SVM_rcv1 =  OneVsRestClassifier(LinearSVC(multi_class='ovr'), n_jobs=40)\n",
    "\n",
    "# rcv1 training set does not contain all the labels and throws a warning.\n",
    "# This with statement will suppress these warnings.\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "    %time clf_SVM_rcv1 = clf_SVM_rcv1.fit(rcv1_train.data, rcv1_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.5 s, sys: 8 ms, total: 18.5 s\n",
      "Wall time: 18.5 s\n",
      "\n",
      "99 unique labels predicted, 103 exist\n",
      "\n",
      "Accuracy: 0.5143\n",
      "macro-averaged F1: 0.4862\n",
      "macro averaged recall: 0.4026\n",
      "macro averaged precision: 0.7872\n"
     ]
    }
   ],
   "source": [
    "from scoring import get_scores, print_scores\n",
    "\n",
    "%time pred_SVM_rcv1 = clf_SVM_rcv1.predict(rcv1_test.data)\n",
    "\n",
    "def check_pred_labels(num_labels, pred):\n",
    "    # np.where returns a tuple where the second item is\n",
    "    # the second dimensional indices where the statement is true.\n",
    "    pred_labels = np.where(pred_SVM_rcv1.todense() == 1)[1]\n",
    "    \n",
    "    pred_unique = np.unique(pred_labels)\n",
    "    \n",
    "    print(f'\\n{pred_unique.shape[0]} unique labels predicted, {num_labels} exist\\n')\n",
    "\n",
    "check_pred_labels(rcv1_test.target.shape[1], pred_SVM_rcv1)\n",
    "    \n",
    "# This will throw an UndefinedMetricWarning because not all labels \n",
    "# will be predicted. Shown above.\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "    scores_SVM_rcv1 = get_scores(rcv1_test.target, pred_SVM_rcv1, 'macro')\n",
    "\n",
    "\n",
    "print_scores(scores_SVM_rcv1, 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scoring import graph_scores\n",
    "\n",
    "graph_scores([scores_SVM_rcv1], ['linear'], 'SVM on RCV1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.8 s, sys: 440 ms, total: 18.2 s\n",
      "Wall time: 18.2 s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 18s, sys: 11 s, total: 1min 29s\n",
      "Wall time: 1min 29s\n"
     ]
    }
   ],
   "source": [
    "from scoring import graph_precision_recall\n",
    "\n",
    "%time confidence_SVM_rcv1 = clf_SVM_rcv1.decision_function(rcv1_test.data)\n",
    "\n",
    "%time graph_precision_recall(rcv1_test.target, [confidence_SVM_rcv1], ['linear'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines on MNIST <a id='svm_mnist'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 51s, sys: 232 ms, total: 4min 52s\n",
      "Wall time: 4min 52s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "from datasets import load_mnist\n",
    "\n",
    "#load mnist dataset\n",
    "mnist_train, mnist_test = load_mnist()\n",
    "\n",
    "#clf_SVM_mnist is a list of SVM classifiers,\n",
    "#one classifier uses a polynomial kernel function while the other \n",
    "#uses a linear kernel.\n",
    "clf_SVM_mnist = [SVC(kernel='poly'), LinearSVC()]\n",
    "%time clf_SVM_mnist = [clf.fit(mnist_train.data, mnist_train.target) for clf in clf_SVM_mnist]\n",
    "\n",
    "titles_SVM_mnist = ['polynomial', 'linear']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 14s, sys: 112 ms, total: 2min 14s\n",
      "Wall time: 2min 14s\n",
      "\n",
      "polynomial\n",
      "Accuracy: 0.9772\n",
      "macro-averaged F1: 0.9770\n",
      "macro averaged recall: 0.9770\n",
      "macro averaged precision: 0.9770\n",
      "\n",
      "linear\n",
      "Accuracy: 0.8348\n",
      "macro-averaged F1: 0.8271\n",
      "macro averaged recall: 0.8312\n",
      "macro averaged precision: 0.8473\n"
     ]
    }
   ],
   "source": [
    "from scoring import get_scores, print_scores\n",
    "\n",
    "#for each classifier generate predicted labels for the test data\n",
    "%time pred_SVM_mnist = [clf.predict(mnist_test.data) for clf in clf_SVM_mnist]\n",
    "\n",
    "scores_SVM_mnist = [get_scores(mnist_test.target, pred, 'macro') for pred in pred_SVM_mnist]\n",
    "\n",
    "for title, score in zip(titles_SVM_mnist, scores_SVM_mnist):\n",
    "    print(f'\\n{title}')\n",
    "    print_scores(score, 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scoring import graph_scores\n",
    "\n",
    "graph_scores(scores_SVM_mnist, titles_SVM_mnist, 'SVM on MNIST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 14s, sys: 124 ms, total: 2min 14s\n",
      "Wall time: 2min 14s\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAEWCAYAAACpPdRYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xt8XHW97//XJ9cm6b0JLW3TpKVAaQu1ECIgCAiWFrGIGxSUvTceBMEfG/kJbD1uFQXBox71bISzKYgXECjgVigXQUVugmBbC6V3SmnpvemVtknTXD7nj++aZkhzmaSZzCXv5+Mxj7VmzZo1n7WSmc/6ftd3fb/m7oiIiEh6ykl1ACIiItI+JWoREZE0pkQtIiKSxpSoRURE0pgStYiISBpTohYREUljStSS1sxssZmd0ck6Y8xsj5nl9lJYSWdmq83s7Gj+O2b2m1THJCKpoUQt3RIlkrooQW42s1+aWf+e/hx3n+TuL3Syznvu3t/dm3r686Mk2RDt504ze9XMTu7pzzkUZjbQzP6Pmb0Xxbkyel6a6thE5NApUcuh+KS79weOB04Evtl6BQsy/f/s4Wg/S4HngUdTHM8BZlYAPAdMAqYDA4FTgG1AdTe2l9ejAYrIIcv0H1BJA+6+HvgDMBnAzF4ws1vN7BWgFhhnZoPM7F4z22hm683se/FV1WZ2hZktNbPdZrbEzI6PlsdXAVeb2Twzez8qxf8kWl5pZh5LMmY20szmmNn2qHR5RdznfMfMHjGz+6LPWmxmVQnuZyPwADDKzMritnmemb0RV+I+Lu61cjP7nZnVmNk2M7sjWn6Emf0lWrbVzB4ws8HdOPz/AowBLnD3Je7e7O5b3P0Wd386+iw3s/FxMf3KzL4XzZ9hZuvM7Gtmtgn4ZfR3OC9u/bwoxtjf5KRoP3ea2ZvxlybM7DIzWxUd23fN7PPd2CcRiaNELYfMzMqBc4EFcYv/GbgSGACsAX4NNALjganANOCL0fsvAr5DSDoDgZmEEmFr/wn8p7sPBI4AHmknpIeAdcBI4ELgNjM7K+71mcBsYDAwB7gjwf0siGLcBuyIlh0P/AL4EjAMmAXMMbPC6ETkyWj/K4FR0ecCGPD9KMZjgPLoGHTV2cAz7r6nG++NGQEMBSoIf7OHgEviXj8H2Oru/zCzUcBTwPei99wA/LeZlZlZCXA7MMPdBxBK9m8cQlwighK1HJrHzGwn8FfgReC2uNd+5e6Lo1LoUGAGcJ2773X3LcBPgYujdb8I/NDd53qw0t3XtPF5DcB4Myt19z3u/lrrFaKThlOBr7n7Pnd/A/g54cQh5q/u/nR0Tft+YEon+/mZaD/rgCuAC6P9Ino+y91fd/cmd/81UA+cRKh6HgncGO33Pnf/K0C0j39y93p3rwF+ApzeSRxtGQZs7Mb74jUDN0Wx1AEPAjPNrDh6/XPRMoBLgaej49fs7n8C5hFO1GLbmmxmRe6+0d0XH2JsIn2eErUcik+5+2B3r3D3L0c/8jFr4+YrgHxgY1RdupNQ8jwser0ceCeBz7scOApYZmZz46tn44wEtrv77rhlawil2ZhNcfO1QL+oevfzUWOsPWb2h7h1HnH3wcBwYBFwQqt9uz62X9G+lUdxlANr4pL6AWZ2mJnNji4DvA/8hnANvKu2AYd3433xatx9X+yJu68ElgKfjJL1TFoSdQVwUav9PRU43N33Ap8FriL8rZ8yswmHGJtIn6dELckSPyzbWkIpszRK7IPdfaC7T4p7/YhON+j+trtfQkjwPwB+G1W3xtsADDWzAXHLxgDrE9j+A1Hr8f7uPqON17cSqri/Y2ax5LgWuDVuvwa7e7G7PxS9NqadBlrfJxyj46Kq/EsJ1eFd9WfgnDaOQ7xaoDju+YhWr7c1hF6s+vt8YEmUvCHs0/2t9rfE3f8XgLs/6+4fJ5w8LAPu6fouiUg8JWpJOnffCPwR+LGFW4lyosZUsarenwM3mNkJFow3s4rW2zGzS82szN2bgZ3R4g/ckuXua4FXge+bWb+oYdflhEZgPbEvy4BngX+PFt0DXGVmH45iLzGzT0QnCn8nVEv/r2h5PzP7SPS+AcAeYGd03ffGboZ0PyF5/reZTYiO7TAz+4aZxaqj3wA+Z2a5ZjadxKrYZxPaEVxNS2kaQsn/k2Z2TrS9flGDtNFmNtzMZkYnDfXR/vX4LXMifY0StfSWfwEKgCWEhli/JaqydfdHgVsJCWE38BjhunZr04HFZraH0LDs4vgq2ziXEBpvbQB+T7j++qce3JcfAVea2WHuPo9wnfqOaL9WApcBRNfAP0loQPceoYHbZ6NtfJdwW9suQuOs33UnEHevJzQoWwb8CXifcIJQCrwerfaVKI6dwOcJx7ez7W4E/kZoEPZw3PK1hFL2N4AawknCjYTfkhzgesJx3044Ifhyd/ZLRFqYe1u1XiIiIpIOVKIWERFJY0rUIiIiaUyJWkREJI0pUYuIiKSxjOuAv7S01CsrK1MdhohIRpk/f/5Wdy/rfE1JNxmXqCsrK5k3b16qwxARyShm1la3vJIBVPUtIiKSxpSoRURE0pgStYiISBpTohYREUljStQiIiJpTIlaREQkjSUtUZvZL8xsi5ktaud1M7PbzWylmS00s+OTFYuIiEimSmaJ+leEYQnbMwM4MnpcCfxXIhv1ZqehtuHAo6lRo3+JiEj2SlqHJ+7+kplVdrDK+cB9HsbZfM3MBpvZ4dE4uO3a8/ZGXjn31gPPm3ILsM9dzJn/NAyrq4XhwyEnPWr03cOjubllGnu4Q24uFBSEcM1SHa2IiKSjVPZMNoow6HzMumjZQYnazK4klLoZM3QUQz9zNgD5L/6ZzZv3w/338eL9Yd0BA2DCBNi7FzbZ4RQeP4nGdZvIHVFG/6oJ1JcMZV9TPqtXh5ze2Ah1dbB/PzQ1heeNjeH5/v3Q0BCWNzeHaWw+PuG2no+fdseAAbH9bpnGz3e2bMsWKCqCww/veN2OXlu9GmprYcqUjt+byLStZc3NsGgRTJ0aTli6G2db62zYAIMGweDB4XnsRCh+vrkZdu0K/wOx1+If8duLf9TXQ0lJ2E7sEb/d2LJDPV4iIjHm3c0miWw8lKifdPfJbbz2FPB9d/9r9Pw54N/dfX5H26yqqvIDXYju2sX7T73M/Hv+wdvjZzB8y1sM3LUWI7F9asgrIq9xH4az4YjTyM1xiup3svnIU2kcNpyCQiM/PySS3NzwAxybtv6RbusHO/611s937oR33oFJk0Lyr6+H116DY48NpexYaRw+OO1smTts2xYSUVFR198fm9bUhPnBg9t+PZFpR6/t35/Qn6hP6ugEp/W0oSFMi4raPsFo/bz1sqam8L9YVtb2CUZXTjLae23HjvA48si2T5paP/bsgZUroaqq/f3o6HlsfufO8F045pgPfn83bgz7GztmiZygxS9vbIR9+2DIkIN/E5qawnbjPy/2SPWJmJnNd/eq1EYh3ZHKRD0LeMHdH4qeLwfO6Kzq+wOJupXNm+G//gtmzICKYXvY8tZmho8tZvfGPeya9zbl+Zso3PwejBtHw/JVFBWFpJiXl8CX6IgjYPduKC+HykooLW359sUX0+rrYft2OOywlm9rW78I7f0a9GHtnTS0nnb2mnv4wWx96SF+vrExJI9Bg9p+f3uPNWvCD3S/fgdfzlizJmx3zJjO96GjaVfWffXV8O84fPjBsbbep7b2EUKNUlNT2KeuHOtE112/Phyfww4LX4f2jm3sb7NrV3hfv34tJw9d2a/WxzJdxBK3WThRLSmB/PyDT/a3bAnrV1aGWq0tW0ItIYRj+Pbb4YS+pCRsr39/GDky/JZ1RIk6c6UyUX8CuAY4F/gwcLu7V3e2zY4S9SFxD8WTV1+FF14Iv8bFxeFXpjfk5YXPjE/cOTnh12vTprDO0KHhGzt27Ae/3fv2wahRLXXmInLghC122So2ra9v+YolciLTelltbfjKDRjQcpLW1BROMLZsCefysc+rrYXXX4eTTmq5dLZ3b5jm57d9+Wzp0vC5lZXhMs7+/eFcv66u4/0977xQC9EeJerMlbREbWYPAWcApcBm4CYgH8Dd7zIzA+4gtAyvBb7g7p1m4KQl6kTs2wdr18KqVTBiREiu8d9gMygsDPV2lZXh2/jKKyG5xopgrYt4tbWhzvuooz74zY09Ghrg3XcTj7F//5Yi0tChLcWTo44Krx1xxAfr4Xfv/mDpPzc3nKoXFKiUL5JmYj8J9fXha755czg5ePllGD8eLr20/fcqUWeupJaokyGliTrV6uvDxeNYNXvs8c47sHx5eO2EE0JyXrky1Ic1NrbUpXXHkCEtSTsnJ5ziQ0jmzc1w3HEhuS9bBuPGhYva69bBxInhJCRW0o/V84lIj/vZz8LX66qr2l9HiTpzZdx41H1aYSGMHn3w8rFj4eyzO35vYyNs3Rrm4+vr3n03JPSmppDoN20KCXnZstBsvH//D74nZu/eMF24MGy7oSFcm49ZtqzjeI49NiTz3NxQtzd0aDghKCoKNRXp0gJHJAMUF6c6AkkmJeq+Ii8vVNe3VlHRMn/MMd3ffuyCYOx+t/r6ULLevj0k8fnzw4W6V18N67/1Vngkorw8bDPWgG/LlpZS+uGHhzq/0tK0uX9epLcVF8P776c6CkkWJWrpGWbhZCAvr6X5cPyJwSc+EabTpoXEvWNHS6k+1gR76dKQcEtKQon9lVfCe3buDCX72HsaGkI7AQjJ/o9/DPMFBWFbZWXh4h2E2oIhQ8J9cHl54f15eaEWInYDt0iGy8lpuaVSso8StfS+/PzQgC1eRQV86EMfXPbxj7e/DfdQhNiwIfTOEruJdc+ekMhjiXrDhvBYvDix2MrLw/SYY0J1/MiRLffBiKSphgZVf2czJWrJTGbhJuhBgzqusm9qCtfd8/JaSu41NaHEXlgYesSor29pWb95c7hmvnZt29srKgql80mTQqlcJA0MGdL+v6xkPiVqyW65uaHleUz8fHv27g2PmppwjX3lytCbCYRr5fPmhQeE6v3m5lDd3twcagsGDAit3xsbw+eNHq3r55JU7uF8U7KTErVIayUl4RGrnj/ttJbXmppClfsLL4Rk7h6S94YN4XlnfaOOGwdnnRUawSl5Sw+JXZmJdecg2UWJWqQrcnNDPeMFF7T9euza+d69YbpzZ+hceuHC8NqqVS0N4SBUyQ8bFh5HHBFOBGK3xQ0apGQuCSkpCdOmpvAvJdlFf1KRnhR/7XzkyJblF1zQ0iH43/8eWrhPmBCun2/fHq6NL1ly8PYKCsLJwfHHQ3V12K5IK7HkrESdnfQnFektOTmhAVpbjdBiVepvvx2ubS9ZEq53xxq5vfJKy+1qxcVhFI5TTw3XwGO3w0mfFbvisn9/aCMp2UWJWiQdxKrUq6NxaU45peW1WDexjz7a8ov87rsf7AO+oiJcU6+oCPWglZW6WNmHxCpamppSG4ckhxK1SLrLyQmDOX/jGy3Ldu8OPb8tXRruI1+zJjzmzv3ge485Bs488+D71iWrxBqTKVFnJyVqkUw0YEBIwrF7yGMjse3cGZL3ypXh+vfSpS3jJubmwhVXtN2VrGS02HXpfftSG4ckhxK1SDYwa7mtbNSoMEiLe+jQ5dVXYcGCUNy6666w/uTJoTHbhAlqfZQFYiXp+HFzJHvoGyqSrcxC3+kzZ4bH2rXwj3+EKvNFi8IDQucsgwbB+eeHblMl48QGuVPVd3ZSohbpK8rLW/oy378/DEX6wgth/PKdO+H228NrY8fCySfDUUelLFTpmlilSGNjauOQ5FCiFumLCgrguOPCA2D9enj++XBtO75F+amnhurxtsZBl7QR6xdn9+7UxiHJoUQtIuG69qWXhuvamzbBf/83bN0Kf/1reEC4day6OlSnS1rRyFnZTYlaRFqYhS5Mr7kmPN+xA37zm9Ao7e9/D4+Yyy6DMWPUzWkaiCXqvXtTG4ckhxK1iLRvyBD4t38LJe21a0OV+PLlYRCSX/0qrDNxYmhFfswx6mQlRQoKwqHvbEwYyUxK1CLSObNQeh4zBk4/PfRPPnduuEd7yZKWfsrHj4d/+qcwbrf0GrNQsbFlS6ojkWRQohaRrhs6FM45Jzz27YM//zmM0b1yJfzgB2Gda67R9exe5K7zo2yli0sicmj69YPzzoObbgrdlcaqv++4Ax54AGpqUhtfHzF4cBgaXbKPStQi0jPMQrX46aeHTlUeeiiMBvb222GYzk9+Utewk8hdt2dlK5WoRaTnjR4NN94Il18env/jH/Dd74ZOViQp8vNDozLJPkrUIpI85eXwrW+FQUQAZs+GH/0INm5MbVxZaMAANSbLVqr6FpHkys2F668Po3s99hisWAGzZoXXvvWtljEa5ZDU1YUxWST7qEQtIr2juBg+9zn46ldbOqe+5RZ49ll1Ut0Dhg7VYcxWStQi0rsGDoRvfhNOOSU8/9vf4HvfC1P31MaWwfLyNHpWtlKiFpHUmDYNvv1tuOCC8PzZZ0ODs23bUhtXhsrNDQOhSfZRohaR1MnJgSlT4D/+I3RDCvCzn8Gdd6o/zC5qaNDl/mylRC0iqZefDxdeCF/6UrjYWlMDt90W+hSXhJSWhqpvXafOPklN1GY23cyWm9lKM/t6G6+PMbPnzWyBmS00s3OTGY+IpLnDD4drr4WzzgrP774bHnxQ2ScBhYVhqoqI7JO0RG1mucCdwAxgInCJmU1stdo3gUfcfSpwMfB/kxWPiGSQ006DL3853G+0YkVobLZsmRqbdSA/P0wbGlIbh/S8ZJaoq4GV7r7K3fcDs4HzW63jwMBofhCgei4RCQ47LPRuNnNmeD57Njz+ODQ3pzauNBW7423fvtTGIT0vmR2ejALWxj1fB3y41TrfAf5oZv8GlABnt7UhM7sSuBJgzJgxPR6oiKSx44+H446DJ5+EN94IfYfPnAlHH53qyNKSrhJkn2SWqNvqfb91vdUlwK/cfTRwLnC/mR0Uk7vf7e5V7l5VVlaWhFBFJK3l5cGnPgWf+ATs3RsG/HjuuVRHlVaGDg3TPXtSG4f0vGQm6nVAedzz0RxctX058AiAu/8N6AdoAFsRaduJJ8LXo3apL78MP/yhrltHiovDVCNoZZ9kJuq5wJFmNtbMCgiNxea0Wuc94CwAMzuGkKg1eK2ItK9fP/jGN8J8bW1I1rpufWDkLI1JnX2SlqjdvRG4BngWWEpo3b3YzG42s6h1CNcDV5jZm8BDwGXuOj0WkU4UFMBNN8GQISEz3Xxzn7/nOpaoc9Q7RtZJ6uhZ7v408HSrZd+Om18CfCSZMYhIljKDr3wF/vQneOWVcM/1eedBVVWqI0uJ2O1Z77+f2jik5+ncS0Qy28c/DtddF+affDIMpdkHWdR8d+vW1MYhPU+JWkQy3+DB8LWvQVlZuIXrwQf7ZCOz3NyWKnDJHkrUIpIdiorgqqtC0XLFijASVx/rT7O0tE+en2Q9JWoRyR65ufCtb4UuSAG+/33YuTO1MfUijUmdnZSoRSS75OSEQT3OPTcUL//zP8NoXH1Abq6G885GStQikp2qq+Gyy0KyvvPOPtHKat++llG0JHsoUYtI9qqsDMka4I47YOPGVEaTdIcdBps2pToK6WlK1CKS3SorQx/hALNmZXXHKA0NoeM2yS5K1CKS/U48Ef71X8P83XfDmjWpjSdJSks1HnU2UqIWkb5h7Fj40pfC/H33webNqY0nCQoLwzCXGuoyuyhRi0jfcfjhcPXVoVeQ2bOzbkzIvKhTaN2ilV2UqEWkbxk+HC66KHSKfdddWZXVYolaJersokQtIn3PuHEwfXooUf/+91nTnVdsYI4+1iFb1kvq6FkiImnrxBNhyxaYOxcGDoRp01Id0SGL3UOtRJ1dVKIWkb7r3HPhiCPg1Vfh3XdTHc0hU4k6OylRi0jfZQYzZoT5X/8aamtTG08PyZLdkIgStYj0baWlcM45YX7WrIxuXFZUFKY5+mXPKvpzioicfHJI1rt2hWrwDKXbs7KTErWICMBJJ8GoUfDyy7B9e6qj6Zbc3DBVos4uStQiIhCuV19wQSiWPvQQNDenOqIui1V596EhuPsEJWoRkZjS0tASvKYmNC7LMLEBOWKtvyU7KFGLiMSbPDncV71mTbjHOoMUFISpWn1nFyVqEZHWrr02TJ96KqNuSs7PDzX3WdaFeZ+nRC0i0lpeHpx3Xph//PHUxtJFOTmhG3PJHkrUIiJtqaqCU06BxYvh9ddTHU3Ciop0H3W20Z9TRKQ9H/tYmP7hD7BvX2pjSVBxcejCXLKHErWISHvy8uDznw/zs2alNpYE5eXB3r2pjkJ6khK1iEhHjjwSRo+GHTvguedSHU2n8vJabtOS7KBELSLSmS98AcrLQ69l69enOpoODRsGjY2pjkJ6khK1iEhncnPhwgvDjcqPP57WfXSq6jv7KFGLiCRi0CD49KdDS60XX0x1NO2KlaYzsAdUaUdeoiua2SigIv497v5SMoISEUlLEyaEa9avvALV1dC/f6ojOsiwYWFaX98y7KVktoRK1Gb2A+AV4JvAjdHjhgTeN93MlpvZSjP7ejvrfMbMlpjZYjN7sAuxi4j0vmnTQnH1lVdSHUmb3MM0Q+4mkwQkWqL+FHC0u9cnumEzywXuBD4OrAPmmtkcd18St86RwP8EPuLuO8zssMRDFxFJgbIyGDIE3noLzjqrZRDoNBErUdfWhjAl8yV6jXoV0NXxWKqBle6+yt33A7OB81utcwVwp7vvAHB33aYvIulvxozQofZTT6U6koMUF4epGpRlj0RPBWuBN8zsOeBAqdrdr+3gPaOAtXHP1wEfbrXOUQBm9gqQC3zH3Z9JMCYRkdQYPx7GjYMFC0I3o2VlqY7ogAEDwnT9ejjqqNTGIj0j0RL1HOAW4FVgftyjI9bGMm/1PA84EjgDuAT4uZkNPmhDZlea2Twzm1dTU5NgyCIiSWIGF1wQ5u+8M7WxtDJwYJhm0KBf0omEErW7/xp4iJYE/WC0rCPrgPK456OBDW2s87i7N7j7u8ByQuJu/fl3u3uVu1eVpdGZq4j0YQMGwAknhPkFC1IbS5ycnHAnWV1dqiORnpJoq+8zgLcJjcP+L7DCzD7aydvmAkea2VgzKwAuJpTM4z0GnBl9RimhKnxVwtGLiKTSueeG6eOPh/uh0kRhIWzcmOoopKckWvX9Y2Cau5/u7h8FzgF+2tEb3L0RuAZ4FlgKPOLui83sZjObGa32LLDNzJYAzwM3uvu27uyIiEivy82Fyy8P83/8Y2pjidPYmNadp0kXJdqYLN/dl8eeuPsKM+u0Fbi7Pw083WrZt+PmHfhq9BARyTzl5WHQjvnzw7CYJSWpjoj+/WHnzlRHIT0l0RL1PDO718zOiB730HljMhGRvuHjHw/TZ9LjppWyMnj//VRHIT0l0UR9NbAYuBb4CrAEuCpZQYmIZJSKCjjiiNAJyrvvpjoaCgvDNI0um8shSLTVd727/8TdP+3uF7j7T7vSS5mISNb77GdDbyOzZ6f83qjDoj4e1elJdugwUZvZI9H0LTNb2PrROyGKiGSAgoLQY1l9fcr7AS8oCFP1950dOmtM9pVoel6yAxERyXjHHgvPPw+vvRZ6LIvVQfey3Nwwra1NycdLD+uwRO3usTvxtgJr3X0NUAhM4eDOS0RE5IILQqn6pdSNAjxoUJju2pWyEKQHJdqY7CWgXzQm9XPAF4BfJSsoEZGMVV4OlZWh+nv9+pSEEBsmW/dSZ4dEE7W5ey3waeBn7n4BMDF5YYmIZLBPfjJMn3664/WSpKQkdCWqEnV2SDhRm9nJwOeB2Lhu6TUIq4hIuhg2LHR+sn49rFzZ6x9vFkrVukadHRJN1NcB/xP4fdQN6DhCl58iItKWqqowXbYsJR9fUKBOT7JFovdRv+juM939B9HzVZ2MRS0i0rcVF8PRR8O8eeCtR/hNvoaGlN/OLT2kw+prM/s/7n6dmT3BwWNJ4+4z23ibiIhA6LFs+fIwDObxx/fqRw8cGK5TS+br7Drz/dH0fyc7EBGRrHPiifCXv8ALL8DUqeHicS8pKoL33uu1j5Mk6jBRu3ts4I15QJ27NwOYWS7hfmoREWlPfn4Ys3rOnFCynjCh1z56//6U9bciPSzRipHngOK450XAn3s+HBGRLHPccaF4O29er37skCG6PStbJJqo+7n7ntiTaL64g/VFRAQgLw9OOincprV8ea99bE6OrlFni0T/jHvN7EBLCDM7AahLTkgiIlnmpJPCtBdL1f37Q3NzShqcSw9LtNOS64BHzSzWv/fhwGeTE5KISJYpLITqapg7F3bvhgEDkv6RedGve1NTy7xkpkTvo54LTACuBr4MHBPX0ExERDpTXR2GtXrmmV792Pr6Xv04SYKEErWZFQNfA77i7m8BlWamoS9FRBJVWhqS9eLFsHlz0j8uNjBHQ0PSP0qSLNFr1L8E9gMnR8/XAd9LSkQiItnqxBPD9MUXk/5R+flhqv6+M1+iifoId/8h0ADg7nVA7925LyKSDYYMCaXqJUt6LYM2N/fKx0gSJZqo95tZEVE3omZ2BKArHyIiXTVpUpgm+Vp1SUmYNjYm9WOkFySaqG8CngHKzewBQgco/560qEREslVFBYwaBYsWwZ49na/fTbm5YaoRtDJfp4nazAxYBnwauAx4CKhy9xeSGpmISLb61KfCDc4vv5y0j4hdo9atWZmv00Tt7g485u7b3P0pd3/S3bf2QmwiItmprAzGjYP585M2FmVBQZiq6jvzJVr1/ZqZnZjUSERE+pKPfjRk0d//Pimbj5Wkd+9OyualFyVaKXImcJWZrQb2Elp8u7sfl6zARESyWkVF6KFs6dKQsHu4jjpW9S2ZL9H/jBlJjUJEpC86++xQol6yJIyy1YP69QvTHTt6dLOSAh1WfZtZPzO7DrgRmA6sd/c1sUevRCgikq0mTw73Uc2d2+Objo2cpVbfma+za9S/BqqAtwil6h8nPSIRkb4iNzck67VrYdOmHt98UZGGuswGnf0JJ7r7pe4+C7gQOK0XYhIR6TtOi35Wk1CqHjxYPZNlg84S9YHu3N1djfxFRHpa//7CO6pLAAAUsElEQVShYVmsUVkPysvT7VnZoLNEPcXM3o8eu4HjYvNm1umVDzObbmbLzWylmX29g/UuNDM3s6qu7oCISMY77bTQ93cPl6pzc5Wos0GHidrdc919YPQY4O55cfMDO3qvmeUCdxKubU8ELjGziW2sNwC4Fni9+7shIpLBxo8PnaDMmxd6LOsh+flJ609FelEymxlUAyvdfZW77wdmA+e3sd4twA+BfUmMRUQkvZ18MmzbBq/3XJmloACamnpsc5IiyUzUo4C1cc/XRcsOMLOpQLm7P9nRhszsSjObZ2bzampqej5SEZFUmzIlTJ95psdagOXlaTzqbJDMRN3WeNUH6nTMLAf4KXB9Zxty97vdvcrdq8rKynowRBGRNJGbCx/7WJhfurRHNtnYCHv39simJIWSmajXAeVxz0cDG+KeDwAmAy9EXZOeBMxRgzIR6bNOPjkUg198sUeuVffrp65Es0EyE/Vc4EgzG2tmBcDFwJzYi+6+y91L3b3S3SuB14CZ7j4viTGJiKSv/HyYNg22bAkNyw5RSQk0NPRo+zRJgaQl6ui+62uAZ4GlwCPuvtjMbjazmcn6XBGRjFYVVSrOn3/Im4oNddnQ0PF6kt6SOqS4uz8NPN1q2bfbWfeMZMYiIpIRcnJg6lRYsABqasJtW91UWBimukUrs6kXWBGRdHPGGWH6/POHtJlYiXqfbn7NaErUIiLpZtAgOProMPzlsmXd3kxJSZhu3dpDcUlKKFGLiKSj86P+od58s9ubiI2cpWvUmU2JWkQkHRUXw0c/Gu6pfu+9bm1i0KAwVavvzKZELSKSrk45JUyffbZbb8+LmgurRJ3ZlKhFRNJVv35wzjmwfn23StWxzk527OjhuKRXKVGLiKSzyZPD9Be/6HIdduz2rFjrb8lMStQiIulswAAYPDjMv/12l96amxumGssosylRi4ikuyuuCNOXXurW24uLezAW6XVK1CIi6a6kJHSCsm5dl0vVJSU9NmqmpIgStYhIJoi1AH/gAWhqSvhtOTldWl3SkBK1iEgmKCgILcChSyNr5eaqC9FMp0QtIpIpTjoJhg6Fl19OuAV4czPs2ZPkuCSplKhFRDKFGUyaFDLvqlUJvaVfPyXqTKdELSKSSU4/PdRnJ9gC3Ez3UWc6JWoRkUySlwcf+hCsWQMbN3a6elmZuhDNdErUIiKZ5mMfC9MEGpUVFkJdXZLjkaRSohYRyTQlJWG86vnzO23SXVioEnWmU6IWEclEp50Wpn/5S4er5ebqPupMp0QtIpKJRo+GceNg4UKor293tbw89UyW6ZSoRUQy1Zlnhqrvv/+93VXU2UnmU6IWEclUo0fD8OHw3HNQW9vmKoMG9XJM0uOUqEVEMpUZTJ8e5ufPb3OV2FCXkrmUqEVEMtnYsVBZCS+80ObF6Bz9ymc8/QlFRDLdhAmhaXcbQ2AqUWc+/QlFRDJdVVW4YXrhwoNeMktBPNKjlKhFRDJdXh5MnAiLF8PevR94SYk68ylRi4hkg6lTw3Tx4g8sLilJQSzSo5SoRUSyQXl5uFVr7twPjFWta9SZT39CEZFsYAbV1VBTA2vXHlicl5fCmKRHKFGLiGSLCRPCdOnSA4uUqDOfErWISLYoKQnJ+m9/O3BPtaq+M19S/4RmNt3MlpvZSjP7ehuvf9XMlpjZQjN7zswqkhmPiEjWKy8P0+ieaiXqzJe0P6GZ5QJ3AjOAicAlZjax1WoLgCp3Pw74LfDDZMUjItInfPjDkJ8Pf/0roESdDZL5J6wGVrr7KnffD8wGzo9fwd2fd/dYT/KvAaOTGI+ISPbLy4OKitCgzF2JOgsk8084Clgb93xdtKw9lwN/aOsFM7vSzOaZ2byampoeDFFEJAsdc0yYbtigDk+yQDITdVv/Ht7GMszsUqAK+FFbr7v73e5e5e5VZWVlPRiiiEgWmhhdZVywgPz81IYihy6ZDffXAeVxz0cDG1qvZGZnA/8BnO7u9UmMR0Skbygqgn79YNMmlaizQDJL1HOBI81srJkVABcDc+JXMLOpwCxgprtvSWIsIiJ9yxFHwObN5HhTqiORQ5S0RO3ujcA1wLPAUuARd19sZjeb2cxotR8B/YFHzewNM5vTzuZERKQrJk2ChgZy1r2X6kjkECW1zxp3fxp4utWyb8fNn53MzxcR6bMqK8GM3DWrgLGpjkYOgRrui4hko+JiGDWKnDXvpjoSOURK1CIi2WrMGGz9ug+MpiWZR4laRCRbDRqEGfTfsynVkcgh0LgqIiLZamy4Nn3YjuXdevv8+fMPy8vL+zkwGRXskqUZWNTY2PjFE044oc27n5SoRUSyVVkZ5OfTf+/mbr09Ly/v5yNGjDimrKxsR05OjurPk6C5udlqamombtq06efAzLbW0RmSiEi2MoNx47qdqIHJZWVl7ytJJ09OTo6XlZXtItRatL1OL8YjIiK9bfhwiuq2d/fdOUrSyRcd43bzsRK1iEg2GzZM3YhmOCVqEZFsVlbWpxJ1dXX10S+99FJxKj576tSpEzpbp7i4eGpXt6tELSKSzQoLUx1Bn7FgwYJlydiuWn2LiGSzoqIe2cxvf8vADRvo0UEzR46k4cILeb+jdZYvX14wffr0I6dOnbp30aJFxePGjdv36KOPrv7LX/5S8vWvf728qamJKVOm1N53331rioqKDlxP/+lPf1q6aNGionvvvXctwI9//OPSpUuX9rvxxhu3zJgx48jq6uo98+bN6z98+PD9zz777Mr+/fv7q6++WnT11VdX1NXV5VRUVNQ/+OCDq8vKypqqq6uPPvbYY2vffPPN4u3bt+f98pe/fPfWW289fPny5UXnn3/+9ttvv30DhNJybW3tgl27duVMnz59/K5du3IbGxvt29/+9oZLL710Z3ePk0rUIiLZrLCQYWWZXfe9evXqfldddVXNihUrlgwYMKD5lltuGf6lL31p7MMPP/zOihUrljQ2NvKjH/2oLP49l19++fY//vGPg+rr6w3gN7/5TemVV165DeC9997rd+21125ZuXLl4kGDBjXdd999QwAuu+yysbfddtu6FStWLJk0aVLd1772tZGx7RUUFDTPmzdv+Re+8IWaiy66aPw999zz3rJlyxY//PDDpZs2bcqN/+zi4uLmp556auWSJUuWvvjiiyu+8Y1vjG5ubu72/qtELSKSzXJzmTD50AvCnZV8k2nEiBH7p02bthfgn//5n7fdeuuth48ePbr+uOOOqwe47LLLtt15552HAQc6DBk4cGDzRz7ykd0PP/zwoGOPPXZfQ0ODVVdX1y1fvrxg1KhR9aecckodwNSpU2tXr15duG3bttzdu3fnfuITn9gDcMUVV2y76KKLxsW2d8EFF+wEmDJlSt348ePrKioqGgDKy8vrV61aVTBixIi62LrNzc123XXXjX7ttdf65+TksGXLloJ169bljRkzprE7+69ELSKS7fJ7tMa611k3W8NdeeWVW2+99dYRRx111L5LL710a2x5QUHBgSry3Nxcr6ur67R2uV+/fg6Qk5NDYWHhgffn5OTQ2Nj4gQBnzZo1dNu2bXlvvfXW0sLCQh81atSxiXxGe1T1LSKS7aZNS3UEh2Tjxo0Ff/7zn0sAHnzwwaFnnHHG++vXry9YtGhRIcB999037LTTTtvd+n0f+9jH9m7cuLHg97///bDLL7+8w5vJhw0b1jRw4MCmZ555pj/AvffeO+zkk0/e0514d+3alVtaWtpQWFjoTzzxxIANGzYUdGc7MSpRi4hkuylTUh3BIRk3bty+X/ziF8O+/OUvV4wdO7b+nnvuWXvKKafsveiii46INSa74YYbatp676c+9akdCxcuLC4rK2vq7HN++ctfvnv11VdXXHvttTljxoypf+ihh1Z3J94vfvGL22fMmDF+8uTJx0yaNKl27Nix+7qznRjzDBv+rKqqyufNm5fqMEREMoqZzXf3qq68580331w9ZcqUrZ2vmTzLly8vOO+88458++23F3fn/Weeeeb46667bvP5559/UIk7nbz55pulU6ZMqWzrNVV9i4hI1tm6dWtuZWXl5H79+jWne5LujKq+RUQkbR199NH7u1OaLi0tbVq9evWiZMTU21SiFhERSWNK1CIiImlMiVpERCSNKVGLiIikMSVqERFJW7FhIVevXp0/ffr0cZ2tn42UqEVEJO1VVlY2PPPMM6uS+RkNDQ3J3Hy36fYsERHp3G9/O5ANG3q20/CRIxu48MKEBvuI7/jk9ttvH/bkk08Orqury3nvvfcKZ8yYsfOuu+5aB/C73/1u4M033zxy//79VlFRUT979uzVgwYNar7hhhsOf+aZZwbX19fnVFVV7XnggQfW5OTkUF1dfXR1dfWe119/vf+5556787vf/e7mHt3HHqAStYiIZJwlS5YUP/bYY6uWLl26eM6cOUNWrlyZv3Hjxrzbbrvt8JdeemnFkiVLlh5//PG1t9xyy3CAG2+8ccuiRYuWvv3224vr6upyZs+ePSi2rZ07d+bOnTt3eTomaVCJWkREEpFgybe3nHrqqe8PGzasCWD8+PH73nnnncLt27fnvvPOO/2qq6snADQ0NNgJJ5ywB+APf/jDgJ/85Ccj9u3bl7Nz5868iRMn1gG7AC655JIOB+xINSVqERHJOK2HqmxoaDB359RTT33/iSeeeDd+3draWrv++usrXn/99SXjx49v+OpXvzpy3759B2qUBwwY0NybsXeVqr5FRCQrnHHGGXvnzZvXPzb85e7du3MWLlxYWFtbmwMwYsSIxl27duU88cQTQ1IbadeoRC0iIllh5MiRjbNmzVp98cUXj9u/f78B3HTTTeuPO+64XZ///OdrJk6cOGn06NH7p0yZsjfVsXaFhrkUEekDMnWYy75Cw1yKiIhkqKQmajObbmbLzWylmX29jdcLzezh6PXXzawymfGIiIhkmqQlajPLBe4EZgATgUvMbGKr1S4Hdrj7eOCnwA+SFY+IiHRZc3Nzs6U6iGwXHeN2W54ns0RdDax091Xuvh+YDZzfap3zgV9H878FzjIz/VOIiKSHRTU1NYOUrJOnubnZampqBgGL2lsnma2+RwFr456vAz7c3jru3mhmu4BhwAcaL5jZlcCV0dN6M2t3h/qYUlodqz5Mx6KFjkULHYsWR3f1DY2NjV/ctGnTzzdt2jQZtWlKlmZgUWNj4xfbWyGZibqtM7DWTcwTWQd3vxu4G8DM5nW15WK20rFooWPRQseihY5FCzPr8u0yJ5xwwhZgZhLCkS5I5hnSOqA87vloYEN765hZHjAISOuu3ERERHpTMhP1XOBIMxtrZgXAxcCcVuvMAf41mr8Q+Itn2o3dIiIiSZS0qu/omvM1wLNALvALd19sZjcD89x9DnAvcL+ZrSSUpC9OYNN3JyvmDKRj0ULHooWORQsdixY6Fhkq43omExER6UvUik9ERCSNKVGLiIiksbRN1Op+tEUCx+KrZrbEzBaa2XNmVpGKOHtDZ8cibr0LzczNLGtvzUnkWJjZZ6L/jcVm9mBvx9hbEviOjDGz581sQfQ9OTcVcSabmf3CzLa019eEBbdHx2mhmR3f2zFKN7h72j0Ijc/eAcYBBcCbwMRW63wZuCuavxh4ONVxp/BYnAkUR/NX9+VjEa03AHgJeA2oSnXcKfy/OBJYAAyJnh+W6rhTeCzuBq6O5icCq1Mdd5KOxUeB44FF7bx+LvAHQh8WJwGvpzpmPTp/pGuJWt2Ptuj0WLj78+5eGz19jXDPejZK5P8C4Bbgh8C+3gyulyVyLK4A7nT3HQDuvqWXY+wtiRwLBwZG84M4uE+HrODuL9FxXxTnA/d58Bow2MwO753opLvSNVG31f3oqPbWcfdGINb9aLZJ5FjEu5xwxpyNOj0WZjYVKHf3J3szsBRI5P/iKOAoM3vFzF4zs+m9Fl3vSuRYfAe41MzWAU8D/9Y7oaWdrv6eSBpIZheih6LHuh/NAgnvp5ldClQBpyc1otTp8FiYWQ5hFLbLeiugFErk/yKPUP19BqGW5WUzm+zuO5McW29L5FhcAvzK3X9sZicT+m+Y7O7tjliUpfrK72ZWSdcStbofbZHIscDMzgb+A5jp7vW9FFtv6+xYDAAmAy+Y2WrCNbg5WdqgLNHvyOPu3uDu7wLLCYk72yRyLC4HHgFw978B/QgDdvQ1Cf2eSHpJ10St7kdbdHosoureWYQkna3XIaGTY+Huu9y91N0r3b2ScL1+prt3eTCCDJDId+QxQkNDzKyUUBW+qlej7B2JHIv3gLMAzOwYQqKu6dUo08Mc4F+i1t8nAbvcfWOqg5KOpWXVtyev+9GMk+Cx+BHQH3g0ak/3nrtn3Yg3CR6LPiHBY/EsMM3MlgBNwI3uvi11USdHgsfieuAeM/v/CVW9l2Xjib2ZPUS41FEaXY+/CcgHcPe7CNfnzwVWArXAF1ITqXSFuhAVERFJY+la9S0iIiIoUYuIiKQ1JWoREZE0pkQtIiKSxpSoRURE0pgStUgrZtZkZm+Y2SIze8LMBvfw9i8zszui+e+Y2Q09uX0RyS5K1CIHq3P3D7n7ZMI9+v9fqgMSkb5LiVqkY38jbtACM7vRzOZGY/l+N275v0TL3jSz+6Nln4zGSl9gZn82s+EpiF9EMlxa9kwmkg7MLJfQ7eS90fNphL6yqwmDG8wxs48C2wj9rH/E3bea2dBoE38FTnJ3N7MvAv9O6CFLRCRhStQiBysyszeASmA+8Kdo+bTosSB63p+QuKcAv3X3rQDuHhscZjTwcDTebwHwbq9ELyJZRVXfIgerc/cPARWEBBu7Rm3A96Pr1x9y9/Hufm+0vK2+eH8G3OHuxwJfIgwEISLSJUrUIu1w913AtcANZpZPGPThf5hZfwAzG2VmhwHPAZ8xs2HR8ljV9yBgfTT/r4iIdIOqvkU64O4LzOxN4GJ3vz8aIvFv0Shle4BLo5GabgVeNLMmQtX4ZcB3CCOarScMuTk2FfsgIplNo2eJiIikMVV9i4iIpDElahERkTSmRC0iIpLGlKhFRETSmBK1iIhIGlOiFhERSWNK1CIiImns/wHirV9lVL5sbgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 532 ms, sys: 308 ms, total: 840 ms\n",
      "Wall time: 434 ms\n"
     ]
    }
   ],
   "source": [
    "from scoring import graph_precision_recall\n",
    "\n",
    "%time confidence_SVM_mnist = [clf.decision_function(mnist_test.data) for clf in clf_SVM_mnist]\n",
    "%time graph_precision_recall(mnist_test.target, confidence_SVM_mnist, titles_SVM_mnist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a target=\"_top\" href=\"http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\">k-Nearest Neighbors (kNN)</a> <a id='knn'></a>\n",
    "\n",
    "This algorithm is not trained like the previous machine learning algorithms. Nearest Neighbors is an instance-based learning algorithm. This means is not trained to the data, each prediction is generated by finding the $k$ nearest neighbors [hart1968]. It works by calculating the distance from a query point to all other points in the training set, and the top k closest points are used to generate a prediction [cover-1967]. The class that belogs to the majority of the k neighbors is the class the query point is predicted to have, this is called majority voting [coomans1982]. \n",
    "\n",
    "To help improve the voting system in kNN it is possible to inversely weight the class label of each of the nearest neighbors based on their distance to the query point [samworth-2012]. The difference between weighted and unweighted kNN is small and decreases as the number of features increases, but for 15 or less features there has been shown to be at least a 5% improvement [samworth 2012].\n",
    "\n",
    "Calculating the distance between the query and all of the training points can be very computationally demanding so an additional algorithm an be implemented to help calculate distance. The two most frequently used algorithms are kd-tree and BallTree. Both are considerably faster than calculating neighbors with brute force, and BallTree performs especially well in high dimensions. Note that tree implementations cannot be applied to sparse data. A kd-tree is a multidimensional binary search tree [bentley-1975]. In a kd-tree each node is a sample, and every level of the tree corresponds to a dimension. On each level the remaining samples are split based on their value in that dimension. This forms a binary search tree that allows nearest neighbor lokoup without calculating the distance for each sample [bentley-1975]. A ball tree is a complete binary tree that segments the data points into regions bounded by hyperspheres called balls [omohundro-1989]. Each ball corresponds to a node and is the smallest ball that can contain the balls corresponding to its children nodes [omohundro-1989]. The leaves of a balltree hold the information while the interior nodes are only used to guide the search [omohundro-1989].\n",
    "\n",
    "Additionally the  <a target=\"_top\" href=\"http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html\">distance metric</a> can be tailored to the dataset. Let $n$ be the number of dimensions in $\\vec{x}$, and let $x_i$ represent the $i^{\\text{th}}$ dimension of $\\vec{x}$.\n",
    "\n",
    "* Euclidean \n",
    "\\begin{equation*}\n",
    "dist(\\vec{x}, \\vec{y}) = \\sum_{i=1}^n (x_i - y_i)^2\n",
    "\\end{equation*}\n",
    "* Manhattan\n",
    "\\begin{equation*}\n",
    "dist(\\vec{x}, \\vec{y}) = \\sum_{i=1}^n \\mid x_i - y_i \\mid\n",
    "\\end{equation*}\n",
    "* Chebyshev\n",
    "\\begin{equation*}\n",
    "dist(\\vec{x}, \\vec{y}) = \\max_{i \\in [1, n]} ( \\mid x_i - y_i \\mid )\n",
    "\\end{equation*}\n",
    "* Minkowski\n",
    "\\begin{equation*}\n",
    "dist(\\vec{x}, \\vec{y}) = ( \\sum_{i=1}^n \\mid x_i - y_i \\mid^p )^{1/p}\n",
    "\\end{equation*}\n",
    "\n",
    "Notice Minowski distance is a generalized form of the other distance formulas. When $p = 1$ it is the same as Manhattan distance, when $p = \\infty$ it is the same as Chebyshev distance, and when $p = 2$ it is the same as Euclidean distance. The value for $p$ can be any real number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-Nearest Neighbors on RCV1 <a id='knn_rcv1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: JOBLIB_TEMP_FOLDER=/home/jovyan/work/tmp\n"
     ]
    }
   ],
   "source": [
    "# This command changes the location of the temp storage for the notebook. Needed when running from docker.\n",
    "%env JOBLIB_TEMP_FOLDER=/home/jovyan/work/tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_rcv1\n",
    "\n",
    "#load the rcv1 dataset if its has not aready been loaded\n",
    "if('rcv1_train' not in locals() or 'rcv1_test' not in locals()):\n",
    "    print('Loading datasets')\n",
    "    rcv1_train, rcv1_test = (fetch_rcv1(subset='train'), fetch_rcv1(subset='test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28min 34s, sys: 1min 31s, total: 30min 5s\n",
      "Wall time: 30min 57s\n"
     ]
    }
   ],
   "source": [
    "#works\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import numpy as np\n",
    "\n",
    "clf_kNN_rcv1 = OneVsRestClassifier(KNeighborsClassifier(n_jobs=-1, algorithm='ball_tree'), n_jobs=-1)\n",
    "\n",
    "# rcv1 training set does not contain all the labels and throws a warning.\n",
    "# This with statement will suppress these warnings.\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "    %time clf_kNN_rcv1.fit(np.array(rcv1_train.data.todense()), np.array(rcv1_train.target.todense()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 43s, sys: 31 s, total: 3min 14s\n",
      "Wall time: 3min 18s\n"
     ]
    }
   ],
   "source": [
    "%time pred_kNN_rcv1_test = clf_kNN_rcv1.predict(np.array(rcv1_test.data[1203].todense()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see kNN is not feasible on RCV1 as the test set has 781265 samples and it took 3.5 minutes to generate a prediction on one. Because of this we can use dimensionality reduction. For this example we will use  <a target=\"_top\" href=\"http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html\">truncated singular value decompisition (SVD)</a>. Truncated SVD is intended to work on tf-idf matricies, and it works on sparce input. Because of this it is ideal for the RCV1 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 200 ms, sys: 0 ns, total: 200 ms\n",
      "Wall time: 198 ms\n",
      "CPU times: user 6.33 s, sys: 376 ms, total: 6.7 s\n",
      "Wall time: 6.7 s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=100) \n",
    "svd.fit(rcv1_train.data)\n",
    "\n",
    "%time train_data_rcv1 = svd.transform(rcv1_train.data)\n",
    "%time test_data_rcv1 = svd.transform(rcv1_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.88 s, sys: 16.5 s, total: 20.3 s\n",
      "Wall time: 21.3 s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import numpy as np\n",
    "\n",
    "#explain why one-v-rest is used\n",
    "clf_kNN_rcv1_reduced = OneVsRestClassifier(KNeighborsClassifier(n_jobs=-1, algorithm='ball_tree'), n_jobs=-1)\n",
    "\n",
    "# rcv1 training set does not contain all the labels and throws a warning.\n",
    "# This with statement will suppress these warnings.\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "    #fit the kNN classifier to a reduced version of the rcv1 dataset\n",
    "    %time clf_kNN_rcv1_reduced.fit(train_data_rcv1, rcv1_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scoring import get_scores, print_scores\n",
    "\n",
    "%time pred_kNN_rcv1 = clf_kNN_rcv1_reduced.predict(test_data_rcv1)\n",
    "\n",
    "scores_kNN_rcv1 = get_scores(rcv1_test.target, pred_kNN_rcv1, 'micro')\n",
    "\n",
    "print_scores(scores_kNN_rcv1, 'micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scoring import graph_scores\n",
    "\n",
    "graph_scores([scores_kNN_rcv1], ['n_components = 100'], 'kNN on RCV1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-Nearest Neighbors on MNIST <a id='knn_mnist'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from datasets import load_mnist\n",
    "\n",
    "#load mnist dataset\n",
    "mnist_train, mnist_test = load_mnist()\n",
    "\n",
    "#clf_kNN_mnist is a list of kNN classifiers each with different weighting schemes or distance metrics\n",
    "#parameter p in the KNeighborClassifier constructor sets distance metric p=1 is equivalent to the manhattan distance\n",
    "#and p=2 is equivalent to the euclidean distance.\n",
    "clf_kNN_mnist = [KNeighborsClassifier(algorithm='ball_tree', p=1, n_jobs=-1),\n",
    "           KNeighborsClassifier(algorithm='ball_tree', weights='distance', p=1, n_jobs=-1),\n",
    "           KNeighborsClassifier(algorithm='ball_tree', weights='distance', p=2, n_jobs=-1),\n",
    "           KNeighborsClassifier(algorithm='ball_tree', metric='chebyshev', n_jobs=-1)]\n",
    "\n",
    "%time clf_kNN_mnist = [clf.fit(mnist_train.data, mnist_train.target) for clf in clf_kNN]\n",
    "\n",
    "titles_kNN_mnist = ['Manhattan', 'Manhattan, Distance Weighted', 'Euclidean, Distance Weighted', 'Chebyshev']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scoring import get_scores, print_scores\n",
    "\n",
    "%time pred_kNN_mnist = [clf.predict(mnist_test.data) for clf in clf_kNN_mnist]\n",
    "\n",
    "scores_kNN_mnist = [get_scores(mnist_test.target, pred, 'macro') for pred in pred_kNN_mnist]\n",
    "\n",
    "for title, score in zip(titles_kNN_mnist, scores_kNN_mnist):\n",
    "    print(f'\\n{title}')\n",
    "    print_scores(score, 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scoring import graph_scores\n",
    "\n",
    "graph_scores(scores_kNN_mnist, titles_kNN_mnist, 'kNN on MNIST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scoring import graph_precision_recall\n",
    "\n",
    "%time confidence_kNN_mnist = [clf.predict_proba(mnist_test.data) for clf in clf_kNN_mnist]\n",
    "%time graph_precision_recall(mnist_test.target, confidence_kNN_mnist, titles_kNN_mnist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a target=\"_top\" href=\"http://scikit-learn.org/stable/modules/tree.html\">Decision Trees</a> <a id='decision_trees'></a>\n",
    "\n",
    "Decision Trees form a heirarchy of rules used to classify a document. Decision trees take the form of a tree, as the name suggests. Each node in the tree is a rule and each child node represents a possible outcome. A decision tree is traversed by starting at the root and moving to the appropriate child node based on the current node's rule. This makes decision trees easy to visualize and interpret. \n",
    "\n",
    "There are several algorithms for building decision trees, the two most popular are Classification and Regression Tree (CART) and C4.5 algorithms. Scikit-learn uses a variation of the CART algorithm.\n",
    "\n",
    "There are two main criterion that can be used to split a decision tree node. \n",
    "1. Gini impurity is typically used with the CART algorithm. Let $p_{mk}$ be the probability of a document being in node $m$ belonging to class $k$. See equation 8.6 from [James 2009].\n",
    "\\begin{equation}\n",
    "G = \\sum^K_{k=1} p_{mk} (1 - p_{mk} )\n",
    "\\end{equation}\n",
    "2. Information gain, or entropy, is typically used with the C4.5 algorithm. See equation 8.7 from [James 2009].\n",
    "\\begin{equation}\n",
    "D = - \\sum^K_{k=1} p_{mk} log( p_{mk} )\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees on RCV1<a id='dt_rcv1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.datasets import fetch_rcv1\n",
    "\n",
    "#load the rcv1 dataset if its has not aready been loaded\n",
    "if('rcv1_train' not in locals() or 'rcv1_test' not in locals()):\n",
    "    print('Loading datasets')\n",
    "    rcv1_train, rcv1_test = (fetch_rcv1(subset='train'), fetch_rcv1(subset='test'))\n",
    "\n",
    "\n",
    "clf_DT_rcv1 = [OneVsRestClassifier(DecisionTreeClassifier(criterion='gini'), n_jobs=-1),\n",
    "          OneVsRestClassifier(DecisionTreeClassifier(criterion='entropy'), n_jobs=-1)]\n",
    "\n",
    "# rcv1 training set does not contain all the labels and throws a warning.\n",
    "# This with statement will suppress these warnings.\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "    %time clf_DT_rcv1 = [clf.fit(rcv1_train.data, rcv1_train.target) for clf in clf_DT_rcv1]\n",
    "\n",
    "titles_DT_rcv1 = ['Gini Impurity', 'Entropy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scoring import get_scores, print_scores\n",
    "\n",
    "%time pred_DT_rcv1 = [clf.predict(rcv1_test.data) for clf in clf_DT_rcv1]\n",
    "\n",
    "scores_DT_rcv1 = [get_scores(rcv1_test.target, pred, 'micro') for pred in pred_DT_rcv1]\n",
    "\n",
    "for title, score in zip(titles_DT_rcv1, scores_DT_rcv1:\n",
    "    print(f'\\n{title}')\n",
    "    print_scores(score, 'micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scoring import graph_scores\n",
    "\n",
    "graph_scores(scores_DT_rcv1, titles_DT_rcv1, 'Decision Trees on RCV1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scoring import graph_precision_recall\n",
    "\n",
    "%time confidence_DT_rcv1 = [clf.predict_proba(rcv1_test.data) for clf in clf_DT_rcv1]\n",
    "%time graph_precision_recall(rcv1_test.target, confidence_DT_rcv1, titles_DT_rcv1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees on MNIST <a id='dt_mnist'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from datasets import load_mnist\n",
    "\n",
    "#load mnist dataset\n",
    "mnist_train, mnist_test = load_mnist()\n",
    "\n",
    "clf_DT_mnist = [DecisionTreeClassifier(criterion='gini'),\n",
    "          DecisionTreeClassifier(criterion='entropy')]\n",
    "\n",
    "%time clf_DT_mnist =  [clf.fit(mnist_train.data, mnist_train.target) for clf in clf_DT_mnist]\n",
    "\n",
    "titles_DT_mnist = ['Gini Impurity', 'Entropy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scoring import get_scores, print_scores\n",
    "\n",
    "%time pred_DT_mnist = [clf.predict(mnist_test.data) for clf in clf_DT_mnist]\n",
    "\n",
    "scores_DT_mnist = [get_scores(mnist_test.target, pred, 'macro') for pred in pred_DT_mnist]\n",
    "\n",
    "for title, score in zip(titles_DT_mnist, scores_DT_mnist):\n",
    "    print(f'\\n{title}')\n",
    "    print_scores(score, 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scoring import graph_scores\n",
    "\n",
    "graph_scores(scores_DT_mnist, titles_DT_mnist, 'Decision Trees on MNIST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scoring import graph_precision_recall\n",
    "\n",
    "%time confidence_DT_mnist = [clf.predict_proba(mnist_test.data) for clf in clf_DT_mnist]\n",
    "%time graph_precision_recall(mnist_test.target, confidence_DT_mnist, titles_DT_mnist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests <a id='random_forests'></a>\n",
    "\n",
    "Random Forests are a kind of ensemble learning algorithm. Ensemble learning algorithms combine multiple machine learning algorithms to improve accuracy. A Random Forest is a collection of Decision Trees where the predictors for splits are chosen at random. On average random forests tend to perform better than a single decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.4, random_state=1)\n",
    "\n",
    "rfc = RandomForestClassifier(criterion='gini', max_depth=2, max_features='sqrt', \n",
    "                             max_leaf_nodes=None, n_jobs=1, random_state=0)\n",
    "\n",
    "\n",
    "rfc.fit(X_train, y_train)\n",
    "rfScore = rfc.score(X_test, y_test)\n",
    "\n",
    "print('Random forest classification accuracy: ' + str(rfScore))\n",
    "\n",
    "\n",
    "\n",
    "dt = DecisionTreeClassifier(criterion='gini')\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "dtScore = dt.score(X_test, y_test)\n",
    "\n",
    "print('Decision tree classification accuracy: ' + str(dtScore))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add random forest on mnsit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
