{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Read In Dataset ([RCV1](http://scikit-learn.org/stable/datasets/rcv1.html))\n",
    "The RCV1 dataset is included in scikit learn by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Trace Cell \"\"\"\n",
    "import time\n",
    "\n",
    "trace = True\n",
    "\n",
    "def ex_time( prev_time , message ):\n",
    "    print(f'Time to {message}: {time.time() - prev_time:0.4f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to fetch: 4.3509 seconds\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Get Dataset Cell\n",
    "\n",
    "    Dependencies:\n",
    "        • Trace Cell \"\"\"\n",
    "\n",
    "from sklearn.datasets import fetch_rcv1\n",
    "\n",
    "def get_rcv1(): \n",
    "    last_time = time.time()\n",
    "\n",
    "    # Retrieve the dataset\n",
    "    rcv1 = fetch_rcv1()\n",
    "    ex_time(last_time, 'fetch')\n",
    "    return rcv1\n",
    "\n",
    "rcv1 = get_rcv1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Attributes\n",
    "   1. __data__ - a scipy [compressed row storage (CSR) sparce matrix](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.sparse.csr_matrix.html). Non-zero values are cosinne-normalized, log TF-IDF vectors. The shape is (num_samples, num_features)\n",
    "   2. __target__ - a scipy CSR sparse matrix. Maps each sample to relavent categories (sometimes refered to as labels). The shape is (num_samples, num_categories).\n",
    "   3. __sample_id__ - a [numpy n-dimensional array](https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.ndarray.html) (ndarray) associating each sample's ID to its sample number\n",
    "   4. __target_names__ - a ndarray of target names (can be thought of as topics or categories) corresponding to the category mapping in __(2)__. Each sample belongs to n categories, where 1 $\\le$ n $\\le$ 13.\n",
    "   5. __description__ - a description of the dataset\n",
    "   \n",
    "The shape attribute gives the dimensions of the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:\n",
      "      shape: (804414, 47236)\n",
      "  data type: float64\n",
      " array type: <class 'scipy.sparse.csr.csr_matrix'>\n",
      "Time to calc nonzero: 0.0107 seconds\n",
      "    nonzero: 3.1463%\n",
      "\n",
      "target:\n",
      "      shape: (804414, 103)\n",
      "  data type: uint8\n",
      " array type: <class 'scipy.sparse.csr.csr_matrix'>\n",
      "Time to calc nonzero: 0.0049 seconds\n",
      "    nonzero: 3.1463%\n",
      "\n",
      "sample_id:\n",
      "      shape: (804414,)\n",
      "  data type: <class 'numpy.uint32'>\n",
      " array type: <class 'numpy.ndarray'>\n",
      "\n",
      "target_names:\n",
      "      shape: (103,)\n",
      "  data type: <class 'str'>\n",
      " array type: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "\"\"\" RCV1 Attributes Cell\n",
    "\n",
    "    Dependencies:\n",
    "        • Get Dataset Cell\n",
    "        • Trace Cell \"\"\"\n",
    "\n",
    "def get_nonzero(matrix):\n",
    "    last_time = time.time()\n",
    "    \n",
    "    nonzero = (matrix.count_nonzero() / (matrix.shape[0] * matrix.shape[1])) * 100\n",
    "    # Check value is valid\n",
    "    assert nonzero <= 100\n",
    "    assert nonzero >= 0\n",
    "    \n",
    "    last_time = ex_time(last_time, 'calc nonzero')\n",
    "    return nonzero\n",
    "\n",
    "def print_rcv1_attributes():\n",
    "    print ('data:')\n",
    "    print(f'      shape: {rcv1.data.shape}')\n",
    "    print(f'  data type: {rcv1.data.dtype}')\n",
    "    print(f' array type: {type(rcv1.data)}')\n",
    "    print(f'    nonzero: {get_nonzero(rcv1.data):0.4f}%\\n')\n",
    "\n",
    "    print('target:')\n",
    "    print(f'      shape: {rcv1.target.shape}')\n",
    "    print(f'  data type: {rcv1.target.dtype}')\n",
    "    print(f' array type: {type(rcv1.target)}')\n",
    "    print(f'    nonzero: {get_nonzero(rcv1.target):0.4f}%\\n')\n",
    "\n",
    "    print('sample_id:')\n",
    "    print(f'      shape: {rcv1.sample_id.shape}')\n",
    "    print(f'  data type: {type(rcv1.sample_id[3])}')\n",
    "    print(f' array type: {type(rcv1.sample_id)}\\n')\n",
    "\n",
    "    print('target_names:')\n",
    "    print(f'      shape: {rcv1.target_names.shape}')\n",
    "    print(f'  data type: {type(rcv1.target_names[3])}')\n",
    "    print(f' array type: {type(rcv1.target_names)}')\n",
    "\n",
    "print_rcv1_attributes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Classification\n",
    "## [Naive Bayes](http://scikit-learn.org/stable/modules/naive_bayes.html)\n",
    "A supervise learning algorithm based on using Bayes' theorem. This method assumes independence between each pair of features.\n",
    "\n",
    "Bayes Theorem:\n",
    "\\begin{equation}\n",
    "P(y | x_1, . . ., x_n) = \\frac{P(y) P(x_1, . . ., x_n | y)} {P(x_1, . . ., x_n)} \\hspace{3.6cm} (1)\n",
    "\\end{equation}\n",
    "\n",
    "This can be further simplified by using the assumption that each pair of features is independent, shown in eq 2.1. Then since $P(x_1, ..., x_n) $ is constant with respect to each input we can use the proportionlity in eq 2.2.\n",
    "\n",
    "\\begin{align}\n",
    "P(y | x_1, . . ., x_n) &= \\frac{P(y) \\prod_{i = 1}^{n} P(x_1, . . ., x_n | y)} {P(x_1, . . ., x_n)} \\hspace{3cm}(2.1)\\\\\n",
    "                 &\\propto P(y) \\prod_{i = 1}^{n} P(x_1, . . ., x_n | y)   \\hspace{3.5cm}(2.2)\n",
    "\\end{align}\n",
    "\n",
    "This gives us our classification rule, shown in eq 3.\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{y} = arg \\max_y P(y) \\prod_{i=1}^{n} P(x_i | y) \\hspace{5.4cm} (3)\n",
    "\\end{equation}\n",
    "\n",
    "SciKit Learn supports several Naive Bayes implimentations. \n",
    "1. __Gaussian Naive Bayes__ - In this implementation the likelihood of the features is assumed to be Gaussian. Gussian distributions are more commonly reffered to as the normal distribution or bell curve. This class does not support sparse matricies.\n",
    "2. __Multinomial Naive Bayes__ - In this implementation the likelihood of the features is assumed to follow a multinomial distribution. Typically used in text classification. This class does support sparse matricies.\n",
    "3. __Bernoulli Naive Bayes__ - This implimentaiton assumes the data follows multivariate Bernoulli distributions. Multiple features are allowed but each one is assumed to be a binary variable.\n",
    "\n",
    "Because of these restrictions only Multinomial Naive Bayes will be appropriate for the RCV1 dataset. There is an additional step required because Naive Bayes does not typically predict multilple labels. This means an additional strategy must be implemented. One commonly used startegy is known as one-vs-all ([one-vs-the-rest](http://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsRestClassifier.html#sklearn.multiclass.OneVsRestClassifier) in scikit learn). This strategy works by using one classifier for each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Fit Classifier Cell \n",
    "\n",
    "    Dependencies:\n",
    "        • Trace Cell \"\"\"\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "def make_fit_NB(data, target, num_jobs=-1):\n",
    "    last_time = time.time()\n",
    "    \n",
    "    # Initialize classifier\n",
    "    classifier = OneVsRestClassifier(MultinomialNB(), n_jobs=num_jobs)\n",
    "\n",
    "    # Train classifier\n",
    "    classifier.fit(data, target)\n",
    "    ex_time(last_time, 'train')\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dependent on make_fit_clf and get_rcv1\n",
    "mult_NB_clf = make_fit_NB(rcv1.data, rcv1.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "When testing a machine learning algorithm it is difficult to determine how a classifier performs by hand, so several metrics are commonly used to evaluate their performance.\n",
    "\n",
    "1. __accuracy__ - The percentage of labels predicted correctly.\n",
    "+ __precision__ - The ratio of true positives to true positives and false positives.\n",
    "+ __recall__ - The ratio of true positives to true positives and false negatives.\n",
    "+ __average precision__ - The weighted mean of the precision achieved at eaach recall threshold.\n",
    "\n",
    "The term 'micro' average reffers to calculating the average of each label weighted with respect to how frequently they occur. This is most appropriate for the RCV1 dataset because the labels do not occur with the same frequency. Information on additional averaging methods can be found [here](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html#sklearn.metrics.average_precision_score). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Scoring Methods Cell\n",
    "    \n",
    "    Dependencies: \n",
    "        • Trace Cell \"\"\"\n",
    "\n",
    "# For scoring methods\n",
    "from sklearn.metrics import accuracy_score, average_precision_score, f1_score, precision_score, recall_score\n",
    "\n",
    "def predict_clf(clf, data):\n",
    "    last_time = time.time()\n",
    "\n",
    "    # Generate prediction on test data\n",
    "    prediction = clf.predict(data)\n",
    "    ex_time(last_time, 'predict')\n",
    "\n",
    "    return prediction\n",
    "\n",
    "\n",
    "def get_scores(target, prediction):\n",
    "    scores = [accuracy_score(target, prediction)]\n",
    "    scores += [f1_score(target, prediction, average='micro')]\n",
    "    scores += [average_precision_score(target.toarray(), prediction.toarray(), average=\"micro\")]\n",
    "    scores += [recall_score(target, prediction, average='micro')]\n",
    "    scores += [precision_score(target, prediction, average='micro' )]\n",
    "    return scores\n",
    "\n",
    "def print_scores(scores):\n",
    "    print(f'Accuracy: {scores[0]:0.4f}')\n",
    "    print(f'Micro-averaged F1: {scores[1]:0.4f}')\n",
    "    print(f'Average precision score, micro-averaged over all classes: {scores[2]:0.4f}')\n",
    "    print(f'Micro averaged recall: {scores[3]:0.4f}')\n",
    "    print(f'Micro averaged recall: {scores[4]:0.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [K-Folds Cross-Validation](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html)\n",
    "\n",
    "To remove bias from a train/test split it is common practice to use K-Folds cross-validation, typically k = 10. This splits the dataset into k segments. With these k segments k - 1 are used to train a classifier while the last one is used to test. This is repeated until all k segments have been used as the testing segment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" kFold Cell\n",
    "    \n",
    "    Dependencies:\n",
    "        • Scoring Methods Cell \n",
    "        • Trace Cell \"\"\"\n",
    "\n",
    "# For train/test split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def k_fold_and_score_NB(data, target, k):\n",
    "    # Initialize train/test split\n",
    "    kf = KFold(n_splits=k)\n",
    "\n",
    "    total_scores = [0] * 5\n",
    "    # Iterate over each train/test split\n",
    "    for train_index, test_index in kf.split(rcv1.data):\n",
    "        X_train = rcv1.data[train_index]\n",
    "        X_test = rcv1.data[test_index]\n",
    "        y_train = rcv1.target[train_index]\n",
    "        y_test = rcv1.target[test_index]\n",
    "\n",
    "        # Train classifier\n",
    "        split_clf = make_fit_NB(X_train, y_train)\n",
    "\n",
    "        # Generate prediction on test data\n",
    "        prediction = predict_clf(split_clf, X_test)\n",
    "\n",
    "        scores = get_scores(y_test, prediction)\n",
    "        total_scores = list(map(sum, zip(scores, total_scores)))\n",
    "\n",
    "    avg_scores = list(map(lambda x: x / k, total_scores))\n",
    "    for score in avg_score:\n",
    "        assert score >= 0.0\n",
    "        assert score <= 1.0\n",
    "\n",
    "    print_scores(avg_scores)\n",
    "    return avg_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold_and_score_NB(rcv1.data, rcv1.target, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes for tomorrow\n",
    "\n",
    "## SciKit\n",
    "\n",
    "+ [multiclass and multilabel algorithms](http://scikit-learn.org/stable/modules/multiclass.html)\n",
    "+ [precision-recall](http://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html#sphx-glr-auto-examples-model-selection-plot-precision-recall-py)\n",
    "+ [average_precision_score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html#sklearn.metrics.average_precision_score)\n",
    "+ [precision_recall_curve](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html#sklearn.metrics.precision_recall_curve)\n",
    "+ [accuracy_score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score)\n",
    "\n",
    "## Markdown\n",
    "\n",
    "+ [math](http://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Typesetting%20Equations.html)\n",
    "+ [general](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Support Vector Machines (SVM)](http://scikit-learn.org/stable/modules/svm.html)\n",
    "\n",
    "A supervised learning that works by seperating the samples into categories seperated by a hyperplane, or set of hyperplanes. Since the hyperplane that that seperates them is not typically unique SVM finds the hyperplane with the maximum distance from any of the categories.\n",
    "\n",
    "SVM use kernel functions to compute the similarity between data points. Some of the most common are:\n",
    "\n",
    "1. linear\n",
    "+ polynomial\n",
    "+ radial basis function (rbf)\n",
    "+ sigmoid\n",
    "\n",
    "The kernel used can significantly impact the accuracy of a classifier. More information on kernels is provided [here](http://scikit-learn.org/stable/modules/metrics.html)\n",
    "\n",
    "Additional source on [SVM](http://dx.doi.org/10.1038/nbt1206-1565 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "def make_fit_SVM(data, target, num_jobs=-1):\n",
    "    last_time = time.time()\n",
    "    \n",
    "    # Initialize classifier\n",
    "    classifier = OneVsRestClassifier(SVC())\n",
    "\n",
    "    # Train classifier\n",
    "    classifier.fit(data, target)\n",
    "    ex_time(last_time, 'train')\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_and_score_SVM(data, target, k):\n",
    "    # Initialize train/test split\n",
    "    kf = KFold(n_splits=k)\n",
    "\n",
    "    total_scores = [0] * 5\n",
    "    # Iterate over each train/test split\n",
    "    for train_index, test_index in kf.split(rcv1.data):\n",
    "        X_train = rcv1.data[train_index]\n",
    "        X_test = rcv1.data[test_index]\n",
    "        y_train = rcv1.target[train_index]\n",
    "        y_test = rcv1.target[test_index]\n",
    "\n",
    "        # Train classifier\n",
    "        basic_SVM = make_fit_SVM(X_train, y_train)\n",
    "\n",
    "        # Generate prediction on test data\n",
    "        prediction = predict_clf(split_clf, X_test)\n",
    "\n",
    "        scores = get_scores(y_test, prediction)\n",
    "        total_scores = list(map(sum, zip(scores, total_scores)))\n",
    "        break\n",
    "\n",
    "    avg_scores = list(map(lambda x: x / k, total_scores))\n",
    "    for score in avg_score:\n",
    "        assert score >= 0.0\n",
    "        assert score <= 1.0\n",
    "\n",
    "    print_scores(avg_scores)\n",
    "    return avg_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold_and_score_SVM(rcv1.data, rcv1.target, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
